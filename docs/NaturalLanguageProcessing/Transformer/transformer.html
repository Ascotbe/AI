
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Transformerä»£ç å®ç° &#8212; AIå­¦ä¹ ç¬”è®°</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'NaturalLanguageProcessing/Transformer/transformer';</script>
    <link rel="icon" href="../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="ä»€ä¹ˆæ˜¯å¾®è°ƒ" href="../../FineTuning/Introduction.html" />
    <link rel="prev" title="å †å å¤šå±‚" href="end.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="AIå­¦ä¹ ç¬”è®° - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="AIå­¦ä¹ ç¬”è®° - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    ğŸ“š AI å­¦ä¹ ç¬”è®° ğŸ§ 
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">å‰ç½®çŸ¥è¯†</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../PrerequisiteKnowledge/%E5%BC%A0%E9%87%8F.html">å¼ é‡</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PrerequisiteKnowledge/%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6.html">å¹¿æ’­æœºåˆ¶</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../PrerequisiteKnowledge/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%BD%B4axis%E5%92%8Cdim.html">æ·±åº¦å­¦ä¹ ä¸­çš„è½´/axis/dimå…¨è§£</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PrerequisiteKnowledge/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC.html">è‡ªåŠ¨æ±‚å¯¼</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PrerequisiteKnowledge/%E5%85%B3%E4%BA%8Etensor%E4%B8%AD%E7%9A%84is_leaf.html">å…³äºtensorä¸­çš„is_leaf</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../PrerequisiteKnowledge/PyTorch%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86.html">PyTorchå›¾åƒå¤„ç†</a></li>




<li class="toctree-l1"><a class="reference internal" href="../../PrerequisiteKnowledge/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html">æ¿€æ´»å‡½æ•°</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">å‡½æ•°è¯¦è§£</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/torch.argmax.html">torch.argmax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/torch.matmul.html">torch.matmul</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/torch.normal.html">torch.normal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/torch.zeros.html">torch.zeros</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/torch.nn.Linear.html">torch.nn.Linear</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/torch.nn.ReLU.html">torch.nn.ReLU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/torch.nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/torch.arange.html">torch.arange</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/torch.meshgrid.html">torch.meshgrid</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../FunctionDetails/variance_and_standard_deviation.html">æ–¹å·®å’Œæ ‡å‡†å·®è®¡ç®—</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">çº¿æ€§ç¥ç»ç½‘ç»œ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../LinearNeuralNetwork/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html">çº¿æ€§å›å½’</a></li>








<li class="toctree-l1"><a class="reference internal" href="../../LinearNeuralNetwork/Softmax%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86.html">Softmax å›å½’åŸç†</a></li>


<li class="toctree-l1"><a class="reference internal" href="../../LinearNeuralNetwork/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.html">äº¤å‰ç†µæŸå¤±å‡½æ•°åŸç†è¯¦è§£</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LinearNeuralNetwork/Softmax%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.html">Softmaxå›å½’ä»£ç å®ç°</a></li>








</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">å¤šå±‚æ„ŸçŸ¥æœº</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../MultilayerPerceptrons/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA.html">å¤šå±‚æ„ŸçŸ¥æœºçš„ç®€æ´å®ç°</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">æ·±åº¦å­¦ä¹ è®¡ç®—</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../DeepLearning/%E5%B1%82%E5%92%8C%E5%9D%97.html">å±‚å’Œå—</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../DeepLearning/%E5%8F%82%E6%95%B0%E7%AE%A1%E7%90%86.html">å‚æ•°ç®¡ç†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../DeepLearning/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82.html">è‡ªå®šä¹‰å±‚</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../DeepLearning/%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6.html">è¯»å†™æ–‡ä»¶</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../DeepLearning/GPU.html">GPU</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">å·ç§¯ç¥ç»ç½‘ç»œ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalNeuralNetwork/conv-layer.html">å›¾åƒå·ç§¯</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalNeuralNetwork/padding-and-strides.html">å¡«å……å’Œæ­¥å¹…</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalNeuralNetwork/channels.html">å¤šè¾“å…¥å¤šè¾“å‡ºé€šé“</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalNeuralNetwork/pooling.html">æ±‡èšå±‚</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalNeuralNetwork/lenet.html">å·ç§¯ç¥ç»ç½‘ç»œï¼ˆLeNetï¼‰</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ç°ä»£å·ç§¯ç¥ç»ç½‘ç»œ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalModern/alexnet.html">æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆAlexNetï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalModern/vgg.html">ä½¿ç”¨å—çš„ç½‘ç»œï¼ˆVGGï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalModern/nin.html">ç½‘ç»œä¸­çš„ç½‘ç»œï¼ˆNiNï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalModern/googlenet.html">å«å¹¶è¡Œè¿ç»“çš„ç½‘ç»œï¼ˆGoogLeNetï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalModern/resnet.html">æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalModern/batch-norm.html">æ‰¹é‡è§„èŒƒåŒ–</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ConvolutionalModern/densenet.html">ç¨ å¯†è¿æ¥ç½‘ç»œï¼ˆDenseNetï¼‰</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">è®¡ç®—æœºæ€§èƒ½</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ComputationalPerformance/async-computation.html">å¼‚æ­¥è®¡ç®—</a></li>


<li class="toctree-l1"><a class="reference internal" href="../../ComputationalPerformance/parameterserver.html">å‚æ•°æœåŠ¡å™¨</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">è®¡ç®—æœºè§†è§‰</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ComputerVision/fine-tuning.html">å¾®è°ƒ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ComputerVision/bounding-box.html">ç›®æ ‡æ£€æµ‹å’Œè¾¹ç•Œæ¡†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ComputerVision/object-detection-dataset.html">ç›®æ ‡æ£€æµ‹æ•°æ®é›†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ComputerVision/anchor.html">é”šæ¡†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ComputerVision/multiscale-object-detection.html">å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ComputerVision/semantic-segmentation-and-dataset.html">è¯­ä¹‰åˆ†å‰²å’Œæ•°æ®é›†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ComputerVision/neural-style.html">é£æ ¼è¿ç§»</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">è‡ªç„¶è¯­è¨€å¤„ç†</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../LLMs.html">ä»€ä¹ˆæ˜¯LLMs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Transformer</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="transformer_introduction.html">Transformerä»‹ç»</a></li>
<li class="toctree-l1"><a class="reference internal" href="seq2seq.html"><strong>Seq2Seq æ¨¡å‹</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="embedding.html">Embedding è¯åµŒå…¥</a></li>
<li class="toctree-l1"><a class="reference internal" href="attention.html">Attention æ³¨æ„åŠ›æœºåˆ¶</a></li>
<li class="toctree-l1"><a class="reference internal" href="positional_encoding.html">Positional Encoding  ä½ç½®ç¼–ç </a></li>
<li class="toctree-l1"><a class="reference internal" href="residuals.html">The Residuals  æ®‹å·®</a></li>
<li class="toctree-l1"><a class="reference internal" href="mask.html">Maskæœºåˆ¶</a></li>
<li class="toctree-l1"><a class="reference internal" href="end.html">å †å å¤šå±‚</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Transformerä»£ç å®ç°</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">å¤§æ¨¡å‹å¾®è°ƒ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../FineTuning/Introduction.html">ä»€ä¹ˆæ˜¯å¾®è°ƒ</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/ascotbe/AI" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/NaturalLanguageProcessing/Transformer/transformer.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Transformerä»£ç å®ç°</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#layernorm"><strong>LayerNorm è®¡ç®—</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#batchnorm1d">BatchNorm1d è®¡ç®—</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">ç¼–ç å™¨</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">å¤šå¤´æ³¨æ„åŠ›</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">ç¼–ç å™¨å—</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">è§£ç å™¨</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="transformer">
<h1>Transformerä»£ç å®ç°<a class="headerlink" href="#transformer" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
</pre></div>
</div>
</div>
</div>
<section id="id1">
<h2>åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œå¯¹åºåˆ—ä¸­çš„æ‰€æœ‰ä½ç½®çš„è¡¨ç¤ºè¿›è¡Œå˜æ¢æ—¶ä½¿ç”¨çš„æ˜¯åŒä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œè¿™å°±æ˜¯ç§°å‰é¦ˆç½‘ç»œæ˜¯<em>åŸºäºä½ç½®çš„</em>ï¼ˆpositionwiseï¼‰çš„åŸå› ã€‚åœ¨ä¸‹é¢çš„å®ç°ä¸­ï¼Œè¾“å…¥<code class="docutils literal notranslate"><span class="pre">X</span></code>çš„å½¢çŠ¶ï¼ˆæ‰¹é‡å¤§å°ï¼Œæ—¶é—´æ­¥æ•°æˆ–åºåˆ—é•¿åº¦ï¼Œéšå•å…ƒæ•°æˆ–ç‰¹å¾ç»´åº¦ï¼‰å°†è¢«ä¸€ä¸ªä¸¤å±‚çš„æ„ŸçŸ¥æœºè½¬æ¢æˆå½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼Œæ—¶é—´æ­¥æ•°ï¼Œ<code class="docutils literal notranslate"><span class="pre">ffn_num_outputs</span></code>ï¼‰çš„è¾“å‡ºå¼ é‡ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PositionWiseFFN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> <span class="c1"># åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ffn_num_input: è¾“å…¥ç‰¹å¾çš„ç»´åº¦ï¼Œå³æ¯ä¸ª token çš„ç‰¹å¾æ•°ã€‚</span>
<span class="sd">    ffn_num_hiddens: éšè—å±‚çš„ç¥ç»å…ƒæ•°é‡ï¼Œæ§åˆ¶ä¸­é—´å±‚çš„å¤æ‚åº¦ã€‚</span>
<span class="sd">    ffn_num_outputs: è¾“å‡ºç‰¹å¾çš„ç»´åº¦ã€‚</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_outputs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># # è¿™æ˜¯ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼ˆçº¿æ€§å˜æ¢ï¼‰ï¼Œå®ƒå°†è¾“å…¥ä» ffn_num_input ç»´åº¦æ˜ å°„åˆ° ffn_num_hiddens ç»´åº¦ã€‚è¿™ä¸€æ­¥çš„ä½œç”¨æ˜¯è¿›è¡Œç»´åº¦å˜æ¢å’Œçº¿æ€§ç»„åˆï¼Œå¸®åŠ©æ¨¡å‹æ•æ‰æ›´å¤šå¤æ‚çš„ç‰¹å¾</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">ffn_num_hiddens</span><span class="p">)</span>
        <span class="c1"># ReLU çš„ä½œç”¨æ˜¯å°†è¾“å…¥ä¸­å°äº 0 çš„éƒ¨åˆ†ç½®ä¸º 0ï¼Œä¿ç•™å¤§äº 0 çš„éƒ¨åˆ†ä¸å˜ï¼Œä»è€Œä¸ºç½‘ç»œå¼•å…¥éçº¿æ€§ç‰¹å¾ï¼Œä½¿å¾—æ¨¡å‹å¯ä»¥æ›´å¥½åœ°æ‹Ÿåˆå¤æ‚çš„éçº¿æ€§å…³ç³»</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="c1"># è¿™æ˜¯ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ï¼Œå°†éšè—å±‚çš„è¾“å‡ºè½¬æ¢å› ffn_num_outputs ç»´åº¦</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span> <span class="n">ffn_num_outputs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>ä¸‹é¢çš„ä¾‹å­æ˜¾ç¤ºï¼Œæ”¹å˜å¼ é‡çš„æœ€é‡Œå±‚ç»´åº¦çš„å°ºå¯¸ï¼Œä¼šæ”¹å˜æˆåŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œçš„è¾“å‡ºå°ºå¯¸ã€‚å› ä¸ºç”¨åŒä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºå¯¹æ‰€æœ‰ä½ç½®ä¸Šçš„è¾“å…¥è¿›è¡Œå˜æ¢ï¼Œæ‰€ä»¥å½“æ‰€æœ‰è¿™äº›ä½ç½®çš„è¾“å…¥ç›¸åŒæ—¶ï¼Œå®ƒä»¬çš„è¾“å‡ºä¹Ÿæ˜¯ç›¸åŒçš„ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ffn</span> <span class="o">=</span> <span class="n">PositionWiseFFN</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># è®¾ç½®å¥½ç»´åº¦</span>
<span class="n">ffn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># ç”¨æ¥å°†æ¨¡å‹åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ã€‚åœ¨è¯„ä¼°æ¨¡å¼ä¸‹ï¼Œåƒ Dropout å’Œ BatchNorm ç­‰è®­ç»ƒæ—¶ç‰¹æœ‰çš„æ“ä½œä¼šè¢«å…³é—­ï¼Œä»è€Œç¡®ä¿æ¨¡å‹è¡Œä¸ºä¸€è‡´</span>
<span class="n">ffn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span> <span class="c1"># 2 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æœ‰ 3 ä¸ª tokenï¼ˆæˆ–ä½ç½®ï¼‰ï¼Œæ¯ä¸ª token æœ‰ 4 ä¸ªç‰¹å¾</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[-0.4082, -0.9014,  0.3697, -0.3377,  0.0818,  0.4002, -0.5420,
          -0.3813],
         [-0.4082, -0.9014,  0.3697, -0.3377,  0.0818,  0.4002, -0.5420,
          -0.3813],
         [-0.4082, -0.9014,  0.3697, -0.3377,  0.0818,  0.4002, -0.5420,
          -0.3813]],

        [[-0.4082, -0.9014,  0.3697, -0.3377,  0.0818,  0.4002, -0.5420,
          -0.3813],
         [-0.4082, -0.9014,  0.3697, -0.3377,  0.0818,  0.4002, -0.5420,
          -0.3813],
         [-0.4082, -0.9014,  0.3697, -0.3377,  0.0818,  0.4002, -0.5420,
          -0.3813]]], grad_fn=&lt;ViewBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h2>æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>ä»¥ä¸‹ä»£ç å¯¹æ¯”ä¸åŒç»´åº¦çš„å±‚è§„èŒƒåŒ–å’Œæ‰¹é‡è§„èŒƒåŒ–çš„æ•ˆæœã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># å±‚å½’ä¸€åŒ–ï¼ˆLayer Normalizationï¼‰</span>
<span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyBatchNorm1d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># æ‰¹å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># åœ¨è®­ç»ƒæ¨¡å¼ä¸‹è®¡ç®—Xçš„å‡å€¼å’Œæ–¹å·®</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;layer norm:&#39;</span><span class="p">,</span> <span class="n">ln</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">batch norm:&#39;</span><span class="p">,</span> <span class="n">bn</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>layer norm: tensor([[-1.0000,  1.0000],
        [-1.0000,  1.0000]], grad_fn=&lt;NativeLayerNormBackward0&gt;) 
batch norm: tensor([[-0.3333, -0.3333],
        [ 0.3333,  0.3333]], grad_fn=&lt;NativeBatchNormBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<section id="layernorm">
<h3><strong>LayerNorm è®¡ç®—</strong><a class="headerlink" href="#layernorm" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> æ˜¯å¯¹æ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ï¼Œå› æ­¤å®ƒå¯¹æ¯ä¸€è¡Œç‹¬ç«‹è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ã€‚</p>
<p>å…¬å¼ï¼š</p>
<p>å¯¹äºæ¯ä¸ªæ ·æœ¬<span class="math notranslate nohighlight">\(X_{i}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text { normalized }=\frac{X_{i}-\mu_{i}}{\sigma_{i}}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu_{i}\)</span>æ˜¯æ ·æœ¬<span class="math notranslate nohighlight">\(i\)</span>çš„å‡å€¼ã€‚</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_{i}\)</span>æ˜¯æ ·æœ¬<span class="math notranslate nohighlight">\(i\)</span>çš„æ ‡å‡†å·®ã€‚</p></li>
</ul>
<p>å…·ä½“åˆ°<span class="math notranslate nohighlight">\(x\)</span>ä¸­çš„æ¯ä¸€è¡Œ:</p>
<ul class="simple">
<li><p>ç¬¬ä¸€è¡Œ<code class="docutils literal notranslate"><span class="pre">X[0]</span> <span class="pre">=</span> <span class="pre">[1,</span> <span class="pre">2]</span></code>çš„å‡å€¼ä¸º<span class="math notranslate nohighlight">\(\mu=1.5\)</span>ï¼Œæ ‡å‡†å·®ä¸º<span class="math notranslate nohighlight">\(\sigma=0.5\)</span>ã€‚</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text { normalized } \_X[0]=\left[\frac{1-1.5}{0.5}, \frac{2-1.5}{0.5}\right]=[-1.0,1.0]\]</div>
<ul class="simple">
<li><p>ç¬¬äºŒè¡Œ<code class="docutils literal notranslate"><span class="pre">X[1]</span> <span class="pre">=</span> <span class="pre">[2,</span> <span class="pre">3]</span></code>çš„å‡å€¼ä¸º<span class="math notranslate nohighlight">\(\mu=2.5\)</span>ï¼Œæ ‡å‡†å·®ä¸º<span class="math notranslate nohighlight">\(\sigma=0.5\)</span>ã€‚</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text { normalized } \_\mathrm{X}[1]=\left[\frac{2-2.5}{0.5}, \frac{3-2.5}{0.5}\right]=[-1.0,1.0]\]</div>
</section>
<section id="batchnorm1d">
<h3>BatchNorm1d è®¡ç®—<a class="headerlink" href="#batchnorm1d" title="Link to this heading">#</a></h3>
<p>å…¬å¼ï¼š</p>
<p>å¯¹äºæ¯ä¸ªç‰¹å¾ï¼ˆåˆ—ï¼‰<span class="math notranslate nohighlight">\(X_{j}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text { normalized }=\frac{X_{j}-\mu_{j}}{\sigma_{j}}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu_{j}\)</span>æ˜¯æ ·æœ¬<span class="math notranslate nohighlight">\(j\)</span>çš„å‡å€¼ã€‚</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_{j}\)</span>æ˜¯æ ·æœ¬<span class="math notranslate nohighlight">\(j\)</span>çš„æ ‡å‡†å·®ã€‚</p></li>
</ul>
<p>å…·ä½“åˆ°<span class="math notranslate nohighlight">\(x\)</span>ä¸­çš„æ¯ä¸€è¡Œ:</p>
<ul class="simple">
<li><p>ç¬¬ä¸€è¡Œ<code class="docutils literal notranslate"><span class="pre">X[:,0]</span> <span class="pre">=</span> <span class="pre">[1,</span> <span class="pre">2]</span></code>çš„å‡å€¼ä¸º<span class="math notranslate nohighlight">\(\mu=1.5\)</span>ï¼Œæ ‡å‡†å·®ä¸º<span class="math notranslate nohighlight">\(\sigma=0.5\)</span>ã€‚</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text { normalized } \_X[:,0]=\left[\frac{1-1.5}{0.5}, \frac{2-1.5}{0.5}\right]=[-1.0,1.0]\]</div>
<ul class="simple">
<li><p>ç¬¬äºŒè¡Œ<code class="docutils literal notranslate"><span class="pre">X[:,1]</span> <span class="pre">=</span> <span class="pre">[2,</span> <span class="pre">3]</span></code>çš„å‡å€¼ä¸º<span class="math notranslate nohighlight">\(\mu=2.5\)</span>ï¼Œæ ‡å‡†å·®ä¸º<span class="math notranslate nohighlight">\(\sigma=0.5\)</span>ã€‚</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text { normalized } \_\mathrm{X}[:,1]=\left[\frac{2-2.5}{0.5}, \frac{3-2.5}{0.5}\right]=[-1.0,1.0]\]</div>
<p>ç°åœ¨å¯ä½¿ç”¨æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–æ¥å®ç°<code class="docutils literal notranslate"><span class="pre">AddNorm</span></code>ç±»ã€‚æš‚é€€æ³•ä¹Ÿè¢«ä½œä¸ºæ­£åˆ™åŒ–æ–¹æ³•ä½¿ç”¨ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">AddNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> <span class="c1"># æ®‹å·®è¿æ¥åè¿›è¡Œå±‚è§„èŒƒåŒ–</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    normalized_shapeï¼ˆå±‚è§„èŒƒåŒ–çš„è¾“å…¥å½¢çŠ¶ï¼‰</span>
<span class="sd">    dropoutï¼ˆä¸¢å¼ƒç‡ï¼‰</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>  <span class="c1"># ç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒä¸€å®šæ¯”ä¾‹çš„ç¥ç»å…ƒï¼ŒDropout åœ¨æ¨¡å‹è¯„ä¼°æ—¶ä¼šè‡ªåŠ¨å…³é—­</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="c1"># åœ¨ Dropout ä¹‹åï¼Œå°† Y ä¸è¾“å…¥å¼ é‡ X è¿›è¡Œé€å…ƒç´ ç›¸åŠ ã€‚è¿™ä¸ªè¿‡ç¨‹å°±æ˜¯æ®‹å·®è¿æ¥ï¼ˆResidual Connectionï¼‰</span>
        <span class="n">_</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">+</span> <span class="n">X</span>
        <span class="c1"># print(_)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>æ®‹å·®è¿æ¥è¦æ±‚ä¸¤ä¸ªè¾“å…¥çš„å½¢çŠ¶ç›¸åŒï¼Œä»¥ä¾¿åŠ æ³•æ“ä½œåè¾“å‡ºå¼ é‡çš„å½¢çŠ¶ç›¸åŒã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">add_norm</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span> <span class="mi">4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">add_norm</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span><span class="n">add_norm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="c1"># å› æ­¤ï¼Œå¦‚æœè¾“å…¥æ˜¯å¸¸æ•°å¼ é‡ï¼ˆå¦‚å…¨ä¸º 2 çš„å¼ é‡ï¼‰ï¼Œåˆ™ç»è¿‡ LayerNorm æ ‡å‡†åŒ–åï¼Œç»“æœå¯èƒ½æ˜¯å…¨ 0ï¼Œå› ä¸ºæ ‡å‡†åŒ–åçš„å‡å€¼ä¸º 0</span>
<span class="c1"># ä½¿ç”¨éšæœºå¼ é‡ä»£æ›¿å…¨ 1 çš„å¼ é‡</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">add_norm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 3, 4])
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]], grad_fn=&lt;NativeLayerNormBackward0&gt;)
tensor([[[-0.4455,  1.7027, -0.3918, -0.8654],
         [ 1.5680,  0.1495, -0.7098, -1.0076],
         [-0.2261, -1.2255, -0.1090,  1.5605]],

        [[-0.5173, -0.7151, -0.4931,  1.7256],
         [ 1.3754, -0.2801,  0.2980, -1.3932],
         [ 0.0335,  0.0546, -1.4568,  1.3688]]],
       grad_fn=&lt;NativeLayerNormBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id3">
<h2>ç¼–ç å™¨<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>æœ‰äº†ç»„æˆTransformerç¼–ç å™¨çš„åŸºç¡€ç»„ä»¶ï¼Œç°åœ¨å¯ä»¥å…ˆå®ç°ç¼–ç å™¨ä¸­çš„ä¸€ä¸ªå±‚ã€‚ä¸‹é¢çš„<code class="docutils literal notranslate"><span class="pre">EncoderBlock</span></code>ç±»åŒ…å«ä¸¤ä¸ªå­å±‚ï¼šå¤šå¤´è‡ªæ³¨æ„åŠ›å’ŒåŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œï¼Œè¿™ä¸¤ä¸ªå­å±‚éƒ½ä½¿ç”¨äº†æ®‹å·®è¿æ¥å’Œç´§éšçš„å±‚è§„èŒƒåŒ–ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">masked_softmax</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;åœ¨æœ€åä¸€ä¸ªè½´ä¸Šæ‰§è¡Œ softmax æ“ä½œï¼Œå¹¶å¯¹æŒ‡å®šå…ƒç´ è¿›è¡Œé®æ©ï¼ˆmaskï¼‰ã€‚</span>

<span class="sd">    å‚æ•°ï¼š</span>
<span class="sd">    - X: 3D å¼ é‡ (batch_size, sequence_length, embedding_dimension)ã€‚</span>
<span class="sd">    - valid_lens: 1D æˆ– 2D å¼ é‡ï¼Œè¡¨ç¤ºæ¯ä¸ªåºåˆ—çš„æœ‰æ•ˆé•¿åº¦ï¼Œç”¨äºé®æ©æ— æ•ˆéƒ¨åˆ†ã€‚</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># å†…éƒ¨å‡½æ•°ï¼Œç”Ÿæˆé®æ©æ©ç å¹¶åº”ç”¨åˆ°è¾“å…¥å¼ é‡ X ä¸Š</span>
    <span class="k">def</span> <span class="nf">_sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># è·å–åºåˆ—çš„æœ€å¤§é•¿åº¦ï¼ˆç¬¬äºŒä¸ªç»´åº¦å¤§å°ï¼‰</span>
        
        <span class="c1"># åˆ›å»ºæ©ç ï¼Œmask: shape æ˜¯ (batch_size, maxlen)</span>
        <span class="c1"># torch.arange(maxlen): ç”Ÿæˆ [0, 1, ..., maxlen-1] åºåˆ—</span>
        <span class="c1"># æ¯”è¾ƒç”Ÿæˆçš„åºåˆ—ä¸æœ‰æ•ˆé•¿åº¦ valid_lenï¼Œç”Ÿæˆ True/False æ©ç </span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&lt;</span> <span class="n">valid_len</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        
        <span class="c1"># å°† X ä¸­æ— æ•ˆä½ç½®çš„å€¼è®¾ç½®ä¸ºæŒ‡å®šå€¼ (value, é»˜è®¤ä¸º 0)</span>
        <span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="c1"># å¦‚æœæ²¡æœ‰æä¾› valid_lensï¼Œç›´æ¥åœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Šæ‰§è¡Œ softmax</span>
    <span class="k">if</span> <span class="n">valid_lens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># è·å–è¾“å…¥å¼ é‡çš„å½¢çŠ¶ (batch_size, seq_len, embedding_dim)</span>

        <span class="c1"># å¦‚æœ valid_lens æ˜¯ 1D å¼ é‡ï¼ˆä»£è¡¨æ¯ä¸ª batch çš„æœ‰æ•ˆé•¿åº¦ç›¸åŒï¼‰</span>
        <span class="k">if</span> <span class="n">valid_lens</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># å°† valid_lens æ‰©å±•ä¸ºä¸ X çš„å½¢çŠ¶åŒ¹é…çš„å¼ é‡</span>
            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">valid_lens</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># å¦‚æœ valid_lens æ˜¯ 2D å¼ é‡ï¼ˆå¯èƒ½æ¯ä¸ªåºåˆ—å’Œ query å¯¹åº”çš„æœ‰æ•ˆé•¿åº¦ä¸åŒï¼‰</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># å°† valid_lens å±•å¹³ä¸º 1D å¼ é‡</span>
            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">valid_lens</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># å¯¹å¼ é‡ X çš„æœ€åä¸€ä¸ªè½´ï¼ˆå³æ¯ä¸ªæ—¶é—´æ­¥çš„åµŒå…¥ï¼‰è¿›è¡Œé®æ©å¤„ç†</span>
        <span class="c1"># å°†æ— æ•ˆå…ƒç´ çš„å€¼è®¾ç½®ä¸º -1e6ï¼ˆåœ¨ softmax ä¸­æ¥è¿‘ -âˆï¼Œå…¶æŒ‡æ•°å€¼ä¼šå˜ä¸º 0ï¼‰</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">_sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">valid_lens</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="mf">1e6</span><span class="p">)</span>

        <span class="c1"># å°†é®æ©åçš„ X é‡æ–°è°ƒæ•´ä¸ºåŸå§‹å½¢çŠ¶ï¼Œå¹¶åœ¨æœ€åä¸€ä¸ªè½´ä¸Šæ‰§è¡Œ softmax</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DotProductAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›æœºåˆ¶ã€‚</span>

<span class="sd">    å‚æ•°ï¼š</span>
<span class="sd">    - dropout: åœ¨æ³¨æ„åŠ›æƒé‡ä¸Šåº”ç”¨çš„ dropout æ¦‚ç‡ã€‚</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>  <span class="c1"># åˆå§‹åŒ– dropout å±‚</span>

    <span class="c1"># å‰å‘ä¼ æ’­å‡½æ•°</span>
    <span class="c1"># å‚æ•°ï¼š</span>
    <span class="c1"># - queries: (batch_size, no. of queries, d)ï¼ŒæŸ¥è¯¢å‘é‡</span>
    <span class="c1"># - keys: (batch_size, no. of key-value pairs, d)ï¼Œé”®å‘é‡</span>
    <span class="c1"># - values: (batch_size, no. of key-value pairs, value dimension)ï¼Œå€¼å‘é‡</span>
    <span class="c1"># - valid_lens: (batch_size,) æˆ– (batch_size, no. of queries)ï¼Œè¡¨ç¤ºæ¯ä¸ªåºåˆ—çš„æœ‰æ•ˆé•¿åº¦</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># è·å–æŸ¥è¯¢å‘é‡çš„æœ€åä¸€ä¸ªç»´åº¦ï¼ˆåµŒå…¥ç»´åº¦ï¼‰</span>
        
        <span class="c1"># è®¡ç®—ç‚¹ç§¯å¾—åˆ†ï¼šqueries @ keys.T / sqrt(d)ï¼Œç¼©æ”¾ä»¥é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
        
        <span class="c1"># é€šè¿‡ masked_softmax è¿›è¡Œ softmax å¹¶é®æ©æ— æ•ˆä½ç½®</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">masked_softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
        
        <span class="c1"># å°†æ³¨æ„åŠ›æƒé‡åº”ç”¨åˆ°å€¼å‘é‡ä¸Šï¼Œå¹¶è¿”å›åŠ æƒç»“æœ</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">),</span> <span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="id4">
<h3>å¤šå¤´æ³¨æ„åŠ›<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>å®ç°å¦‚ä¸‹</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€‚</span>
<span class="sd">    </span>
<span class="sd">    å‚æ•°ï¼š</span>
<span class="sd">    - num_hiddens: éšè—å±‚çš„å¤§å°ï¼Œå³è¾“å…¥/è¾“å‡ºçš„åµŒå…¥ç»´åº¦ã€‚</span>
<span class="sd">    - num_heads: æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€‚</span>
<span class="sd">    - dropout: åœ¨æ³¨æ„åŠ›æƒé‡ä¸Šçš„ dropout æ¯”ç‡ã€‚</span>
<span class="sd">    - bias: æ˜¯å¦åœ¨çº¿æ€§å±‚ä¸­ä½¿ç”¨åç½®ã€‚</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>  <span class="c1"># å¤šå¤´çš„æ•°é‡</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">DotProductAttention</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>  <span class="c1"># ç‚¹ç§¯æ³¨æ„åŠ›æœºåˆ¶</span>
        
        <span class="c1"># å®šä¹‰å››ä¸ªçº¿æ€§å˜æ¢ï¼Œåˆ†åˆ«ç”¨äº queriesã€keysã€values å’Œæœ€ç»ˆçš„è¾“å‡º</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>  <span class="c1"># æŸ¥è¯¢çš„çº¿æ€§å˜æ¢</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>  <span class="c1"># é”®çš„çº¿æ€§å˜æ¢</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>  <span class="c1"># å€¼çš„çº¿æ€§å˜æ¢</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>  <span class="c1"># è¾“å‡ºçš„çº¿æ€§å˜æ¢</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        å‚æ•°ï¼š</span>
<span class="sd">        - queries: æŸ¥è¯¢å‘é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, num_queries, num_hiddens)</span>
<span class="sd">        - keys: é”®å‘é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, num_kv_pairs, num_hiddens)</span>
<span class="sd">        - values: å€¼å‘é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, num_kv_pairs, num_hiddens)</span>
<span class="sd">        - valid_lens: æœ‰æ•ˆé•¿åº¦ï¼Œå½¢çŠ¶ä¸º (batch_size,) æˆ– (batch_size, num_queries)</span>
<span class="sd">        </span>
<span class="sd">        è¿”å›ï¼š</span>
<span class="sd">        - è¾“å‡ºå¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, num_queries, num_hiddens)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># å°† queries, keys, values é€šè¿‡å„è‡ªçš„çº¿æ€§å±‚ï¼Œå¹¶è½¬æ¢å½¢çŠ¶ä»¥é€‚åº”å¤šå¤´æ³¨æ„åŠ›</span>
        <span class="c1"># å½¢çŠ¶å˜ä¸º (batch_size * num_heads, num_queries or num_kv_pairs, num_hiddens / num_heads)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">queries</span><span class="p">))</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">keys</span><span class="p">))</span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_v</span><span class="p">(</span><span class="n">values</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">valid_lens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># å°† valid_lens æ‰©å±•ä¸ºä¸æ¯ä¸ªæ³¨æ„åŠ›å¤´ç›¸å¯¹åº”çš„å½¢çŠ¶</span>
            <span class="c1"># é‡å¤ valid_lens num_heads æ¬¡ï¼Œä»¥é€‚åº”å¤šä¸ªå¤´çš„å¹¶è¡Œè®¡ç®—</span>
            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
                <span class="n">valid_lens</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># é€šè¿‡ç‚¹ç§¯æ³¨æ„åŠ›è®¡ç®—ç»“æœï¼Œå½¢çŠ¶ä¸º (batch_size * num_heads, num_queries, num_hiddens / num_heads)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
        
        <span class="c1"># å°†ç»“æœä»å¤šä¸ªå¤´åˆå¹¶ï¼Œå½¢çŠ¶å˜ä¸º (batch_size, num_queries, num_hiddens)</span>
        <span class="n">output_concat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_output</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        
        <span class="c1"># è¿”å›ç»è¿‡çº¿æ€§å˜æ¢åçš„è¾“å‡ºç»“æœ</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span><span class="p">(</span><span class="n">output_concat</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ç”¨äºå¹¶è¡Œè®¡ç®—å¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œè½¬æ¢ queries, keys æˆ– values çš„å½¢çŠ¶ã€‚</span>
<span class="sd">        </span>
<span class="sd">        å‚æ•°ï¼š</span>
<span class="sd">        - X: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, num_queries or num_kv_pairs, num_hiddens)</span>
<span class="sd">        </span>
<span class="sd">        è¿”å›ï¼š</span>
<span class="sd">        - è½¬ç½®åçš„å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size * num_heads, num_queries or num_kv_pairs, num_hiddens / num_heads)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># é¦–å…ˆå°† X çš„æœ€åä¸€ä¸ªç»´åº¦åˆ†æˆ num_heads ä»½ï¼Œå³ (batch_size, num_queries or num_kv_pairs, num_heads, num_hiddens / num_heads)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># äº¤æ¢ç»´åº¦ï¼Œä½¿ num_heads åœ¨ç¬¬äºŒä¸ªç»´åº¦ï¼Œå³ (batch_size, num_heads, num_queries or num_kv_pairs, num_hiddens / num_heads)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        
        <span class="c1"># å°†å‰ä¸¤ä¸ªç»´åº¦åˆå¹¶ï¼Œå½¢çŠ¶å˜ä¸º (batch_size * num_heads, num_queries or num_kv_pairs, num_hiddens / num_heads)</span>
        <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">transpose_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;é€†è½¬ transpose_qkv æ“ä½œï¼Œå°†å¤šä¸ªå¤´çš„è¾“å‡ºç»“æœé‡æ–°ç»„åˆã€‚</span>
<span class="sd">        </span>
<span class="sd">        å‚æ•°ï¼š</span>
<span class="sd">        - X: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size * num_heads, num_queries, num_hiddens / num_heads)</span>
<span class="sd">        </span>
<span class="sd">        è¿”å›ï¼š</span>
<span class="sd">        - åˆå¹¶åçš„å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, num_queries, num_hiddens)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># å°† X è½¬æ¢å› (batch_size, num_heads, num_queries, num_hiddens / num_heads)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        
        <span class="c1"># äº¤æ¢ç»´åº¦å›åˆ° (batch_size, num_queries, num_heads, num_hiddens / num_heads)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        
        <span class="c1"># åˆå¹¶æœ€åä¸¤ä¸ªç»´åº¦ï¼Œè¿”å› (batch_size, num_queries, num_hiddens)</span>
        <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h3>ç¼–ç å™¨å—<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EncoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transformer ç¼–ç å™¨å—ã€‚</span>
<span class="sd">    </span>
<span class="sd">    å‚æ•°ï¼š</span>
<span class="sd">    - num_hiddens: éšè—å±‚çš„ç»´åº¦å¤§å°ã€‚</span>
<span class="sd">    - ffn_num_hiddens: å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFFNï¼‰éšè—å±‚çš„ç»´åº¦å¤§å°ã€‚</span>
<span class="sd">    - num_heads: å¤šå¤´æ³¨æ„åŠ›ä¸­çš„å¤´çš„æ•°é‡ã€‚</span>
<span class="sd">    - dropout: Dropout æ¦‚ç‡ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚</span>
<span class="sd">    - use_bias: æ˜¯å¦åœ¨çº¿æ€§å±‚ä¸­ä½¿ç”¨åç½®ã€‚</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span>
                 <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># å®šä¹‰å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="p">)</span>
        
        <span class="c1"># ç¬¬ä¸€æ¬¡åŠ æ³•å½’ä¸€åŒ–å±‚ï¼Œé€šå¸¸åœ¨å¤šå¤´æ³¨æ„åŠ›åè¿›è¡Œæ®‹å·®è¿æ¥å’Œå½’ä¸€åŒ–</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        
        <span class="c1"># å®šä¹‰ä½ç½®å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆPosition-Wise FFNï¼‰</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">PositionWiseFFN</span><span class="p">(</span><span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        
        <span class="c1"># ç¬¬äºŒæ¬¡åŠ æ³•å½’ä¸€åŒ–å±‚ï¼Œé€šå¸¸åœ¨å‰é¦ˆç½‘ç»œåè¿›è¡Œæ®‹å·®è¿æ¥å’Œå½’ä¸€åŒ–</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        å‚æ•°ï¼š</span>
<span class="sd">        - X: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, num_tokens, num_hiddens)ã€‚</span>
<span class="sd">        - valid_lens: æœ‰æ•ˆé•¿åº¦ï¼Œå½¢çŠ¶ä¸º (batch_size,) æˆ– (batch_size, num_queries)ã€‚</span>
<span class="sd">        </span>
<span class="sd">        è¿”å›ï¼š</span>
<span class="sd">        - è¾“å‡ºå¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, num_tokens, num_hiddens)ã€‚</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># è¿›è¡Œå¤šå¤´æ³¨æ„åŠ›è®¡ç®—ï¼Œå¹¶é€šè¿‡ç¬¬ä¸€ä¸ª AddNorm æ‰§è¡Œæ®‹å·®è¿æ¥å’Œå½’ä¸€åŒ–</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">))</span>
        
        <span class="c1"># é€šè¿‡å‰é¦ˆç¥ç»ç½‘ç»œè®¡ç®—ç»“æœï¼Œå†ç»è¿‡ç¬¬äºŒä¸ª AddNorm æ‰§è¡Œæ®‹å·®è¿æ¥å’Œå½’ä¸€åŒ–</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>æ­£å¦‚ä»ä»£ç ä¸­æ‰€çœ‹åˆ°çš„ï¼ŒTransformerç¼–ç å™¨ä¸­çš„ä»»ä½•å±‚éƒ½ä¸ä¼šæ”¹å˜å…¶è¾“å…¥çš„å½¢çŠ¶ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">24</span><span class="p">))</span>
<span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">encoder_blk</span> <span class="o">=</span> <span class="n">EncoderBlock</span><span class="p">(</span> <span class="mi">24</span><span class="p">,</span>  <span class="mi">48</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">encoder_blk</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">encoder_blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 100, 24])
</pre></div>
</div>
</div>
</div>
<p>ä¸‹é¢å®ç°çš„Transformerç¼–ç å™¨çš„ä»£ç ä¸­ï¼Œå †å äº†<code class="docutils literal notranslate"><span class="pre">num_layers</span></code>ä¸ª<code class="docutils literal notranslate"><span class="pre">EncoderBlock</span></code>ç±»çš„å®ä¾‹ã€‚ç”±äºè¿™é‡Œä½¿ç”¨çš„æ˜¯å€¼èŒƒå›´åœ¨<span class="math notranslate nohighlight">\(-1\)</span>å’Œ<span class="math notranslate nohighlight">\(1\)</span>ä¹‹é—´çš„å›ºå®šä½ç½®ç¼–ç ï¼Œå› æ­¤é€šè¿‡å­¦ä¹ å¾—åˆ°çš„è¾“å…¥çš„åµŒå…¥è¡¨ç¤ºçš„å€¼éœ€è¦å…ˆä¹˜ä»¥åµŒå…¥ç»´åº¦çš„å¹³æ–¹æ ¹è¿›è¡Œé‡æ–°ç¼©æ”¾ï¼Œç„¶åå†ä¸ä½ç½®ç¼–ç ç›¸åŠ ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ç¼–ç å™¨--è§£ç å™¨æ¶æ„çš„åŸºç¡€ç¼–ç å™¨æ¥å£&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># å¯ä»¥æ·»åŠ é¢å¤–çš„å‚æ•° (ä¾‹å¦‚æ’é™¤å¡«å……çš„é•¿åº¦)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>  <span class="c1"># è¿™æ˜¯ä¸€ä¸ªæŠ½è±¡æ–¹æ³•ï¼Œå­ç±»éœ€è¦å®ç°å®ƒ</span>

<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ä½ç½®ç¼–ç ï¼Œå¸®åŠ©æ¨¡å‹æ•æ‰åºåˆ—ä¸­æ¯ä¸ªå…ƒç´ çš„ä½ç½®&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>  <span class="c1"># å®šä¹‰ Dropout å±‚</span>
        <span class="c1"># åˆ›å»ºè¶³å¤Ÿé•¿çš„ P çŸ©é˜µæ¥å­˜å‚¨ä½ç½®ç¼–ç </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>  <span class="c1"># åˆå§‹åŒ–ä½ç½®ç¼–ç çŸ©é˜µ P</span>
        
        <span class="c1"># è®¡ç®—ä½ç½®ç¼–ç å€¼</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
            <span class="mi">10000</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># å¶æ•°ç»´åº¦ä½¿ç”¨ sin å‡½æ•°</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># å¥‡æ•°ç»´åº¦ä½¿ç”¨ cos å‡½æ•°</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># å°†è¾“å…¥ X ä¸ä½ç½®ç¼–ç  P ç›¸åŠ ï¼Œç„¶ååº”ç”¨ Dropout</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># è¿”å›åŠ ä¸Šä½ç½®ç¼–ç åçš„ç»“æœ</span>


<span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">Encoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transformer ç¼–ç å™¨ï¼ŒåŒ…å«å¤šå±‚ EncoderBlock&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span>
                 <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_blks</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span>
        <span class="c1"># åµŒå…¥å±‚ï¼šå°†è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•æ˜ å°„åˆ° embeddingï¼ˆåµŒå…¥ï¼‰å‘é‡</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="c1"># ä½ç½®ç¼–ç å±‚ï¼šåŠ ä¸Šä½ç½®ç¼–ç ä¿¡æ¯</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        
        <span class="c1"># ä½¿ç”¨ nn.Sequential å †å å¤šä¸ª EncoderBlock</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_blks</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;block&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
                <span class="n">EncoderBlock</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
        <span class="c1"># è¯åµŒå…¥ + ä½ç½®ç¼–ç </span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">))</span>
        
        <span class="c1"># åˆå§‹åŒ– attention_weights ç”¨äºå­˜å‚¨æ¯ä¸€å±‚çš„æ³¨æ„åŠ›æƒé‡</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">)</span>
        
        <span class="c1"># ä¾æ¬¡é€šè¿‡æ¯ä¸€ä¸ª EncoderBlock</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">blk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
            <span class="c1"># ä¿å­˜æ¯ä¸ªå—ä¸­çš„æ³¨æ„åŠ›æƒé‡</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span>
        
        <span class="k">return</span> <span class="n">X</span>  <span class="c1"># è¾“å‡ºæœ€ç»ˆçš„ç¼–ç å™¨ç»“æœ</span>
</pre></div>
</div>
</div>
</div>
<p>ä¸‹é¢æˆ‘ä»¬æŒ‡å®šäº†è¶…å‚æ•°æ¥åˆ›å»ºä¸€ä¸ªä¸¤å±‚çš„Transformerç¼–ç å™¨ã€‚
Transformerç¼–ç å™¨è¾“å‡ºçš„å½¢çŠ¶æ˜¯ï¼ˆæ‰¹é‡å¤§å°ï¼Œæ—¶é—´æ­¥æ•°ç›®ï¼Œ<code class="docutils literal notranslate"><span class="pre">num_hiddens</span></code>ï¼‰ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span>
    <span class="mi">200</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">encoder</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span> <span class="n">valid_lens</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 100, 24])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id6">
<h2>è§£ç å™¨<a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<p>Transformerè§£ç å™¨ä¹Ÿæ˜¯ç”±å¤šä¸ªç›¸åŒçš„å±‚ç»„æˆã€‚åœ¨<code class="docutils literal notranslate"><span class="pre">DecoderBlock</span></code>ç±»ä¸­å®ç°çš„æ¯ä¸ªå±‚åŒ…å«äº†ä¸‰ä¸ªå­å±‚ï¼šè§£ç å™¨è‡ªæ³¨æ„åŠ›ã€â€œç¼–ç å™¨-è§£ç å™¨â€æ³¨æ„åŠ›å’ŒåŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œã€‚è¿™äº›å­å±‚ä¹Ÿéƒ½è¢«æ®‹å·®è¿æ¥å’Œç´§éšçš„å±‚è§„èŒƒåŒ–å›´ç»•ã€‚</p>
<p>æ­£å¦‚åœ¨æœ¬èŠ‚å‰é¢æ‰€è¿°ï¼Œåœ¨æ©è”½å¤šå¤´è§£ç å™¨è‡ªæ³¨æ„åŠ›å±‚ï¼ˆç¬¬ä¸€ä¸ªå­å±‚ï¼‰ä¸­ï¼ŒæŸ¥è¯¢ã€é”®å’Œå€¼éƒ½æ¥è‡ªä¸Šä¸€ä¸ªè§£ç å™¨å±‚çš„è¾“å‡ºã€‚å…³äº<em>åºåˆ—åˆ°åºåˆ—æ¨¡å‹</em>ï¼ˆsequence-to-sequence modelï¼‰ï¼Œåœ¨è®­ç»ƒé˜¶æ®µï¼Œå…¶è¾“å‡ºåºåˆ—çš„æ‰€æœ‰ä½ç½®ï¼ˆæ—¶é—´æ­¥ï¼‰çš„è¯å…ƒéƒ½æ˜¯å·²çŸ¥çš„ï¼›ç„¶è€Œï¼Œåœ¨é¢„æµ‹é˜¶æ®µï¼Œå…¶è¾“å‡ºåºåˆ—çš„è¯å…ƒæ˜¯é€ä¸ªç”Ÿæˆçš„ã€‚å› æ­¤ï¼Œåœ¨ä»»ä½•è§£ç å™¨æ—¶é—´æ­¥ä¸­ï¼Œåªæœ‰ç”Ÿæˆçš„è¯å…ƒæ‰èƒ½ç”¨äºè§£ç å™¨çš„è‡ªæ³¨æ„åŠ›è®¡ç®—ä¸­ã€‚ä¸ºäº†åœ¨è§£ç å™¨ä¸­ä¿ç•™è‡ªå›å½’çš„å±æ€§ï¼Œå…¶æ©è”½è‡ªæ³¨æ„åŠ›è®¾å®šäº†å‚æ•°<code class="docutils literal notranslate"><span class="pre">dec_valid_lens</span></code>ï¼Œä»¥ä¾¿ä»»ä½•æŸ¥è¯¢éƒ½åªä¼šä¸è§£ç å™¨ä¸­æ‰€æœ‰å·²ç»ç”Ÿæˆè¯å…ƒçš„ä½ç½®ï¼ˆå³ç›´åˆ°è¯¥æŸ¥è¯¢ä½ç½®ä¸ºæ­¢ï¼‰è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TransformerDecoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transformer è§£ç å™¨çš„ç¬¬ i ä¸ªå—&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">=</span> <span class="n">i</span>  <span class="c1"># è®°å½•è¯¥å—çš„ç´¢å¼• i</span>
        
        <span class="c1"># å®šä¹‰ç¬¬ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ (è‡ªæ³¨æ„åŠ›)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention1</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>  <span class="c1"># Add &amp; Norm æ“ä½œ</span>
        
        <span class="c1"># å®šä¹‰ç¬¬äºŒä¸ªå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ (ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention2</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>  <span class="c1"># Add &amp; Norm æ“ä½œ</span>
        
        <span class="c1"># å®šä¹‰å‰é¦ˆç¥ç»ç½‘ç»œ (FFN)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">PositionWiseFFN</span><span class="p">(</span><span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm3</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>  <span class="c1"># Add &amp; Norm æ“ä½œ</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># æå–ç¼–ç å™¨çš„è¾“å‡ºå’Œæœ‰æ•ˆé•¿åº¦</span>
        <span class="c1"># state[2][self.i] å­˜å‚¨çš„æ˜¯åˆ°å½“å‰æ—¶é—´æ­¥ä¸ºæ­¢ï¼Œç¬¬ i ä¸ªå—çš„è§£ç è¾“å‡º</span>

        <span class="c1"># åœ¨é¢„æµ‹é˜¶æ®µï¼Œéœ€è¦å°†å…ˆå‰çš„è§£ç ç»“æœè¿æ¥åˆ°å½“å‰è¾“å…¥ä¸Š</span>
        <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">key_values</span> <span class="o">=</span> <span class="n">X</span>  <span class="c1"># å¦‚æœè¿™æ˜¯ç¬¬ä¸€æ¬¡è§£ç ï¼Œç›´æ¥ä½¿ç”¨ X</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">key_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">],</span> <span class="n">X</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># å°†ä¹‹å‰çš„ç»“æœä¸å½“å‰è¾“å…¥æ‹¼æ¥</span>
        <span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">key_values</span>  <span class="c1"># æ›´æ–°çŠ¶æ€</span>
        
        <span class="c1"># å¦‚æœæ˜¯åœ¨è®­ç»ƒé˜¶æ®µï¼Œç”Ÿæˆè§£ç å™¨çš„æœ‰æ•ˆé•¿åº¦</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
            <span class="c1"># ç”Ÿæˆå½¢å¦‚ [1, 2, ..., num_steps] çš„æœ‰æ•ˆé•¿åº¦çŸ©é˜µ</span>
            <span class="n">dec_valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dec_valid_lens</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># åœ¨é¢„æµ‹é˜¶æ®µï¼Œæ— éœ€æä¾›è§£ç å™¨çš„æœ‰æ•ˆé•¿åº¦</span>
        
        <span class="c1"># **è‡ªæ³¨æ„åŠ›**ï¼šå¯¹è¾“å…¥ X è¿›è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—ï¼Œä½¿ç”¨ key_values ä½œä¸ºæ³¨æ„åŠ›é”®å’Œå€¼</span>
        <span class="n">X2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">key_values</span><span class="p">,</span> <span class="n">key_values</span><span class="p">,</span> <span class="n">dec_valid_lens</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X2</span><span class="p">)</span>  <span class="c1"># å°†è‡ªæ³¨æ„åŠ›çš„è¾“å‡ºä¸è¾“å…¥ X ç›¸åŠ å¹¶è§„èŒƒåŒ–</span>
        
        <span class="c1"># **ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›**ï¼šå¯¹ç¼–ç å™¨çš„è¾“å‡º (enc_outputs) è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—</span>
        <span class="n">Y2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention2</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">)</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y2</span><span class="p">)</span>  <span class="c1"># å°†ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›çš„è¾“å‡ºä¸ Y ç›¸åŠ å¹¶è§„èŒƒåŒ–</span>
        
        <span class="c1"># **å‰é¦ˆç¥ç»ç½‘ç»œ**ï¼šå¯¹ Z è¿›è¡Œå‰é¦ˆç¥ç»ç½‘ç»œå¤„ç†</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm3</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">Z</span><span class="p">)),</span> <span class="n">state</span>  <span class="c1"># è¾“å‡ºè§„èŒƒåŒ–åçš„ç»“æœå’Œæ›´æ–°åçš„çŠ¶æ€</span>
</pre></div>
</div>
</div>
</div>
<p>ä¸ºäº†ä¾¿äºåœ¨â€œç¼–ç å™¨ï¼è§£ç å™¨â€æ³¨æ„åŠ›ä¸­è¿›è¡Œç¼©æ”¾ç‚¹ç§¯è®¡ç®—å’Œæ®‹å·®è¿æ¥ä¸­è¿›è¡ŒåŠ æ³•è®¡ç®—ï¼Œç¼–ç å™¨å’Œè§£ç å™¨çš„ç‰¹å¾ç»´åº¦éƒ½æ˜¯<code class="docutils literal notranslate"><span class="pre">num_hiddens</span></code>ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">decoder_blk</span> <span class="o">=</span> <span class="n">TransformerDecoderBlock</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">24</span><span class="p">))</span>
<span class="n">state</span> <span class="o">=</span> <span class="p">[</span><span class="n">encoder_blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">),</span> <span class="n">valid_lens</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]]</span>
<span class="n">decoder_blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 100, 24])
</pre></div>
</div>
</div>
</div>
<p>ç°åœ¨æˆ‘ä»¬æ„å»ºäº†ç”±<code class="docutils literal notranslate"><span class="pre">num_layers</span></code>ä¸ª<code class="docutils literal notranslate"><span class="pre">DecoderBlock</span></code>å®ä¾‹ç»„æˆçš„å®Œæ•´çš„Transformerè§£ç å™¨ã€‚æœ€åï¼Œé€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚è®¡ç®—æ‰€æœ‰<code class="docutils literal notranslate"><span class="pre">vocab_size</span></code>ä¸ªå¯èƒ½çš„è¾“å‡ºè¯å…ƒçš„é¢„æµ‹å€¼ã€‚è§£ç å™¨çš„è‡ªæ³¨æ„åŠ›æƒé‡å’Œç¼–ç å™¨è§£ç å™¨æ³¨æ„åŠ›æƒé‡éƒ½è¢«å­˜å‚¨ä¸‹æ¥ï¼Œæ–¹ä¾¿æ—¥åå¯è§†åŒ–çš„éœ€è¦ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„åŸºæœ¬è§£ç å™¨æ¥å£&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_all_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="c1"># åˆå§‹åŒ–çŠ¶æ€</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># è§£ç å™¨çš„å‰å‘ä¼ æ’­</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

<span class="k">class</span> <span class="nc">AttentionDecoder</span><span class="p">(</span><span class="n">Decoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„è§£ç å™¨æ¥å£&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">attention_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># æ³¨æ„åŠ›æƒé‡çš„è·å–</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

<span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">AttentionDecoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transformerè§£ç å™¨&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span>
                 <span class="n">num_blks</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span>  <span class="c1"># éšè—å±‚å¤§å°</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_blks</span> <span class="o">=</span> <span class="n">num_blks</span>  <span class="c1"># è§£ç å™¨å—çš„æ•°é‡</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>  <span class="c1"># è¯åµŒå…¥å±‚</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>  <span class="c1"># ä½ç½®ç¼–ç </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>  <span class="c1"># ä½¿ç”¨Sequentialå®¹å™¨å †å è§£ç å—</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_blks</span><span class="p">):</span>
            <span class="c1"># æ·»åŠ å¤šä¸ªè§£ç å™¨å—ï¼Œæ¯ä¸ªå—éƒ½æ˜¯ä¸€ä¸ªTransformerDecoderBlock</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;block&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">TransformerDecoderBlock</span><span class="p">(</span>
                <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>  <span class="c1"># å…¨è¿æ¥å±‚ï¼Œç”¨äºç”Ÿæˆé¢„æµ‹ç»“æœ</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">):</span>
        <span class="c1"># åˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€ï¼ŒåŒ…å«ç¼–ç å™¨çš„è¾“å‡ºã€æœ‰æ•ˆé•¿åº¦å’Œæ¯ä¸ªè§£ç å—çš„å†å²çŠ¶æ€</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_blks</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># å‰å‘ä¼ æ’­</span>
        <span class="c1"># å¯¹è¾“å…¥Xè¿›è¡Œè¯åµŒå…¥ï¼Œç„¶ååŠ ä¸Šä½ç½®ç¼–ç </span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">))</span>
        <span class="c1"># åˆå§‹åŒ–æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºä¿å­˜è‡ªæ³¨æ„åŠ›å’Œç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›çš„æƒé‡</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span> <span class="o">=</span> <span class="p">[[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">blk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">):</span>
            <span class="c1"># é€šè¿‡æ¯ä¸ªè§£ç å—è¿›è¡Œå‰å‘ä¼ æ’­</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
            <span class="c1"># è®°å½•è‡ªæ³¨æ„åŠ›æƒé‡</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attention1</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span>
            <span class="c1"># è®°å½•ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›æƒé‡</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attention2</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span>
        <span class="c1"># å°†æœ€åçš„è¾“å‡ºé€šè¿‡å…¨è¿æ¥å±‚ç”Ÿæˆæœ€ç»ˆçš„é¢„æµ‹ç»“æœ</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">state</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">attention_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># è¿”å›ä¿å­˜çš„æ³¨æ„åŠ›æƒé‡</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h2><a class="headerlink" href="#id7" title="Link to this heading">#</a></h2>
<p>è®­ç»ƒ
ä¾ç…§Transformeræ¶æ„æ¥å®ä¾‹åŒ–ç¼–ç å™¨ï¼è§£ç å™¨æ¨¡å‹ã€‚åœ¨è¿™é‡Œï¼ŒæŒ‡å®šTransformerçš„ç¼–ç å™¨å’Œè§£ç å™¨éƒ½æ˜¯2å±‚ï¼Œéƒ½ä½¿ç”¨4å¤´æ³¨æ„åŠ›ã€‚ä¸ºäº†è¿›è¡Œåºåˆ—åˆ°åºåˆ—çš„å­¦ä¹ ï¼Œä¸‹é¢åœ¨â€œè‹±è¯­ï¼æ³•è¯­â€æœºå™¨ç¿»è¯‘æ•°æ®é›†ä¸Šè®­ç»ƒTransformeræ¨¡å‹ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä» d2l åº“ä¸­è·å–æ•°æ®é›†ï¼Œæ•°æ®é›†ä¸ºè‹±æ³•ç¿»è¯‘ï¼Œä½¿ç”¨æ‰¹é‡å¤§å° 128</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">MTFraEng</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>

<span class="c1"># å®šä¹‰æ¨¡å‹å‚æ•°</span>
<span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_blks</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.2</span>  <span class="c1"># éšè—å±‚å¤§å°ã€ç¼–ç å™¨å—æ•°ã€dropout æ¦‚ç‡</span>
<span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">4</span>  <span class="c1"># å‰é¦ˆç¥ç»ç½‘ç»œéšè—å±‚å¤§å°å’Œå¤šå¤´æ³¨æ„åŠ›å¤´æ•°</span>

<span class="c1"># åˆ›å»ºç¼–ç å™¨</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">src_vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span>
    <span class="n">num_blks</span><span class="p">,</span> <span class="n">dropout</span>
<span class="p">)</span>

<span class="c1"># åˆ›å»ºè§£ç å™¨</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">TransformerDecoder</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span>
    <span class="n">num_blks</span><span class="p">,</span> <span class="n">dropout</span>
<span class="p">)</span>

<span class="c1"># åˆ›å»º Seq2Seq æ¨¡å‹ï¼ŒæŒ‡å®šè§£ç å™¨çš„å¡«å……ç¬¦å·å’Œå­¦ä¹ ç‡</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Seq2Seq</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">tgt_pad</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">],</span>
                    <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># åˆ›å»ºè®­ç»ƒå™¨ï¼Œè®¾ç½®æœ€å¤§è®­ç»ƒè½®æ•°ã€æ¢¯åº¦è£å‰ªå€¼å’Œ GPU æ•°é‡</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># è®­ç»ƒæ¨¡å‹</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/93c5870a24444130dd9d0ea4b1897db6c448843a2c46a5e70d8c34781c7debe7.svg" src="../../_images/93c5870a24444130dd9d0ea4b1897db6c448843a2c46a5e70d8c34781c7debe7.svg" /></div>
</div>
<p>è®­ç»ƒç»“æŸåï¼Œä½¿ç”¨Transformeræ¨¡å‹å°†ä¸€äº›è‹±è¯­å¥å­ç¿»è¯‘æˆæ³•ï¼Œå¹¶ä¸”è®¡ç®—å®ƒä»¬çš„BLEUåˆ†æ•°ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># å®šä¹‰ä¸€ç»„è‹±è¯­å¥å­å’Œå¯¹åº”çš„æ³•è¯­å¥å­</span>
<span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;go .&#39;</span><span class="p">,</span> <span class="s1">&#39;i lost .&#39;</span><span class="p">,</span> <span class="s1">&#39;he</span><span class="se">\&#39;</span><span class="s1">s calm .&#39;</span><span class="p">,</span> <span class="s1">&#39;i</span><span class="se">\&#39;</span><span class="s1">m home .&#39;</span><span class="p">]</span>
<span class="n">fras</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;va !&#39;</span><span class="p">,</span> <span class="s1">&#39;j</span><span class="se">\&#39;</span><span class="s1">ai perdu .&#39;</span><span class="p">,</span> <span class="s1">&#39;il est calme .&#39;</span><span class="p">,</span> <span class="s1">&#39;je suis chez moi .&#39;</span><span class="p">]</span>

<span class="c1"># ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹</span>
<span class="n">preds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_step</span><span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">),</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">(),</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span>
<span class="p">)</span>

<span class="c1"># éå†æ¯ä¸ªè¾“å…¥å¥å­ã€å‚è€ƒå¥å­å’Œæ¨¡å‹é¢„æµ‹ç»“æœ</span>
<span class="k">for</span> <span class="n">en</span><span class="p">,</span> <span class="n">fr</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">,</span> <span class="n">preds</span><span class="p">):</span>
    <span class="n">translation</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºç›®æ ‡è¯­è¨€çš„ tokens</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="o">.</span><span class="n">to_tokens</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">:</span>  <span class="c1"># é‡åˆ°ç»“æŸç¬¦æ—¶åœæ­¢</span>
            <span class="k">break</span>
        <span class="n">translation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>  <span class="c1"># æ·»åŠ åˆ°ç¿»è¯‘åˆ—è¡¨ä¸­</span>
    <span class="c1"># è¾“å‡ºæºå¥å­ã€ç¿»è¯‘ç»“æœåŠå…¶ BLEU åˆ†æ•°</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">en</span><span class="si">}</span><span class="s1"> =&gt; </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">, bleu,&#39;</span>
          <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">d2l</span><span class="o">.</span><span class="n">bleu</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">translation</span><span class="p">),</span><span class="w"> </span><span class="n">fr</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>go . =&gt; [&#39;va&#39;, &#39;!&#39;], bleu,1.000
i lost . =&gt; [&quot;j&#39;ai&quot;, &#39;perdu&#39;, &#39;.&#39;], bleu,1.000
he&#39;s calm . =&gt; [&#39;il&#39;, &#39;est&#39;, &#39;mouillÃ©&#39;, &#39;.&#39;], bleu,0.658
i&#39;m home . =&gt; [&#39;je&#39;, &#39;suis&#39;, &#39;chez&#39;, &#39;moi&#39;, &#39;.&#39;], bleu,1.000
</pre></div>
</div>
</div>
</div>
<p>å½“è¿›è¡Œæœ€åä¸€ä¸ªè‹±è¯­åˆ°æ³•è¯­çš„å¥å­ç¿»è¯‘å·¥ä½œæ—¶ï¼Œè®©æˆ‘ä»¬å¯è§†åŒ–Transformerçš„æ³¨æ„åŠ›æƒé‡ã€‚ç¼–ç å™¨è‡ªæ³¨æ„åŠ›æƒé‡çš„å½¢çŠ¶ä¸ºï¼ˆç¼–ç å™¨å±‚æ•°ï¼Œæ³¨æ„åŠ›å¤´æ•°ï¼Œ<code class="docutils literal notranslate"><span class="pre">num_steps</span></code>æˆ–æŸ¥è¯¢çš„æ•°ç›®ï¼Œ<code class="docutils literal notranslate"><span class="pre">num_steps</span></code>æˆ–â€œé”®ï¼å€¼â€å¯¹çš„æ•°ç›®ï¼‰ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä½¿ç”¨æ¨¡å‹çš„ predict_step æ–¹æ³•é¢„æµ‹æœ€åä¸€å¯¹è‹±è¯­å¥å­å’Œæ³•è¯­å¥å­ï¼Œå¹¶è·å–è§£ç å™¨æ³¨æ„åŠ›æƒé‡</span>
<span class="n">_</span><span class="p">,</span> <span class="n">dec_attention_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_step</span><span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">build</span><span class="p">([</span><span class="n">engs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="n">fras</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">(),</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># è¿æ¥ç¼–ç å™¨çš„æ‰€æœ‰æ³¨æ„åŠ›æƒé‡</span>
<span class="n">enc_attention_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># é‡æ–°è°ƒæ•´ç¼–ç å™¨æ³¨æ„åŠ›æƒé‡çš„å½¢çŠ¶</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_blks</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>
<span class="n">enc_attention_weights</span> <span class="o">=</span> <span class="n">enc_attention_weights</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># æ£€æŸ¥ç¼–ç å™¨æ³¨æ„åŠ›æƒé‡çš„å½¢çŠ¶æ˜¯å¦ç¬¦åˆé¢„æœŸ</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">enc_attention_weights</span><span class="p">,</span>
                <span class="p">(</span><span class="n">num_blks</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>åœ¨ç¼–ç å™¨çš„è‡ªæ³¨æ„åŠ›ä¸­ï¼ŒæŸ¥è¯¢å’Œé”®éƒ½æ¥è‡ªç›¸åŒçš„è¾“å…¥åºåˆ—ã€‚å› ä¸ºå¡«å……è¯å…ƒæ˜¯ä¸æºå¸¦ä¿¡æ¯çš„ï¼Œå› æ­¤é€šè¿‡æŒ‡å®šè¾“å…¥åºåˆ—çš„æœ‰æ•ˆé•¿åº¦å¯ä»¥é¿å…æŸ¥è¯¢ä¸ä½¿ç”¨å¡«å……è¯å…ƒçš„ä½ç½®è®¡ç®—æ³¨æ„åŠ›ã€‚æ¥ä¸‹æ¥ï¼Œå°†é€è¡Œå‘ˆç°ä¸¤å±‚å¤šå¤´æ³¨æ„åŠ›çš„æƒé‡ã€‚æ¯ä¸ªæ³¨æ„åŠ›å¤´éƒ½æ ¹æ®æŸ¥è¯¢ã€é”®å’Œå€¼çš„ä¸åŒçš„è¡¨ç¤ºå­ç©ºé—´æ¥è¡¨ç¤ºä¸åŒçš„æ³¨æ„åŠ›ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä½¿ç”¨ d2l åº“ä¸­çš„ show_heatmaps å‡½æ•°æ¥å¯è§†åŒ–ç¼–ç å™¨çš„æ³¨æ„åŠ›æƒé‡</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">show_heatmaps</span><span class="p">(</span>
    <span class="n">enc_attention_weights</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>  <span class="c1"># å°†æ³¨æ„åŠ›æƒé‡ç§»åˆ° CPU ä»¥è¿›è¡Œå¯è§†åŒ–</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Key positions&#39;</span><span class="p">,</span>  <span class="c1"># X è½´æ ‡ç­¾ï¼Œè¡¨ç¤ºé”®çš„ä½ç½®</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Query positions&#39;</span><span class="p">,</span>  <span class="c1"># Y è½´æ ‡ç­¾ï¼Œè¡¨ç¤ºæŸ¥è¯¢çš„ä½ç½®</span>
    <span class="n">titles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Head </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>  <span class="c1"># çƒ­å›¾æ ‡é¢˜ï¼Œè¡¨ç¤ºä¸åŒçš„æ³¨æ„åŠ›å¤´</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>  <span class="c1"># è®¾ç½®å›¾å½¢çš„å¤§å°</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/70fdf7295713c2d3e89da8f473a4f93eee5c4368f637131af481e1d87b38e46a.svg" src="../../_images/70fdf7295713c2d3e89da8f473a4f93eee5c4368f637131af481e1d87b38e46a.svg" /></div>
</div>
<p>ä¸ºäº†å¯è§†åŒ–è§£ç å™¨çš„è‡ªæ³¨æ„åŠ›æƒé‡å’Œâ€œç¼–ç å™¨ï¼è§£ç å™¨â€çš„æ³¨æ„åŠ›æƒé‡ï¼Œæˆ‘ä»¬éœ€è¦å®Œæˆæ›´å¤šçš„æ•°æ®æ“ä½œå·¥ä½œã€‚ä¾‹å¦‚ç”¨é›¶å¡«å……è¢«æ©è”½ä½çš„æ³¨æ„åŠ›æƒé‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè§£ç å™¨çš„è‡ªæ³¨æ„åŠ›æƒé‡å’Œâ€œç¼–ç å™¨ï¼è§£ç å™¨â€çš„æ³¨æ„åŠ›æƒé‡éƒ½æœ‰ç›¸åŒçš„æŸ¥è¯¢ï¼šå³ä»¥<em>åºåˆ—å¼€å§‹è¯å…ƒ</em>ï¼ˆbeginning-of-sequence,BOSï¼‰æ‰“å¤´ï¼Œå†ä¸åç»­è¾“å‡ºçš„è¯å…ƒå…±åŒç»„æˆåºåˆ—ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># å°†è§£ç å™¨çš„æ³¨æ„åŠ›æƒé‡è½¬æ¢ä¸ºäºŒç»´åˆ—è¡¨ï¼Œå¡«å……ä¸º 0</span>
<span class="n">dec_attention_weights_2d</span> <span class="o">=</span> <span class="p">[</span><span class="n">head</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1"># æå–ç¬¬ä¸€ä¸ªå¤´çš„æ³¨æ„åŠ›æƒé‡ï¼Œå¹¶è½¬æ¢ä¸ºåˆ—è¡¨</span>
                            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">dec_attention_weights</span>  <span class="c1"># éå†æ¯ä¸ªæ—¶é—´æ­¥</span>
                            <span class="k">for</span> <span class="n">attn</span> <span class="ow">in</span> <span class="n">step</span>  <span class="c1"># éå†æ¯ä¸ªå—çš„æ³¨æ„åŠ›</span>
                            <span class="k">for</span> <span class="n">blk</span> <span class="ow">in</span> <span class="n">attn</span>  <span class="c1"># éå†æ¯ä¸ªå—</span>
                            <span class="k">for</span> <span class="n">head</span> <span class="ow">in</span> <span class="n">blk</span><span class="p">]</span>  <span class="c1"># éå†æ¯ä¸ªå¤´</span>

<span class="c1"># ä½¿ç”¨ pandas DataFrame æ¥å¡«å…… NaN å€¼ï¼Œå¡«å……ä¸º 0.0</span>
<span class="n">dec_attention_weights_filled</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dec_attention_weights_2d</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>  <span class="c1"># å°†å¡«å……åçš„æ•°æ®è½¬æ¢ä¸º PyTorch å¼ é‡</span>

<span class="c1"># è°ƒæ•´å½¢çŠ¶ä»¥åˆ†ç¦»è§£ç å™¨è‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_blks</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>  <span class="c1"># ç›®æ ‡å½¢çŠ¶</span>
<span class="n">dec_attention_weights</span> <span class="o">=</span> <span class="n">dec_attention_weights_filled</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># é‡å¡‘ä¸ºç›®æ ‡å½¢çŠ¶</span>

<span class="c1"># é€šè¿‡ permute æ¥åˆ†ç¦»è§£ç å™¨çš„è‡ªæ³¨æ„åŠ›æƒé‡å’Œäº¤å‰æ³¨æ„åŠ›æƒé‡</span>
<span class="n">dec_self_attention_weights</span><span class="p">,</span> <span class="n">dec_inter_attention_weights</span> <span class="o">=</span> \
    <span class="n">dec_attention_weights</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># æ£€æŸ¥è§£ç å™¨è‡ªæ³¨æ„åŠ›æƒé‡çš„å½¢çŠ¶</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">dec_self_attention_weights</span><span class="p">,</span>
                <span class="p">(</span><span class="n">num_blks</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">))</span>  <span class="c1"># åº”ä¸º (num_blks, num_heads, data.num_steps, data.num_steps)</span>

<span class="c1"># æ£€æŸ¥è§£ç å™¨äº¤å‰æ³¨æ„åŠ›æƒé‡çš„å½¢çŠ¶</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">dec_inter_attention_weights</span><span class="p">,</span>
                <span class="p">(</span><span class="n">num_blks</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">))</span>  <span class="c1"># åº”ä¸º (num_blks, num_heads, data.num_steps, data.num_steps)</span>
</pre></div>
</div>
</div>
</div>
<p>ç”±äºè§£ç å™¨è‡ªæ³¨æ„åŠ›çš„è‡ªå›å½’å±æ€§ï¼ŒæŸ¥è¯¢ä¸ä¼šå¯¹å½“å‰ä½ç½®ä¹‹åçš„â€œé”®ï¼å€¼â€å¯¹è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä½¿ç”¨ d2l.show_heatmaps å‡½æ•°å¯è§†åŒ–è§£ç å™¨è‡ªæ³¨æ„åŠ›æƒé‡</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">show_heatmaps</span><span class="p">(</span>
    <span class="n">dec_self_attention_weights</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:],</span>  <span class="c1"># æå–æ‰€æœ‰å—å’Œå¤´çš„è‡ªæ³¨æ„åŠ›æƒé‡</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Key positions&#39;</span><span class="p">,</span>  <span class="c1"># X è½´æ ‡ç­¾è¡¨ç¤º Key ä½ç½®</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Query positions&#39;</span><span class="p">,</span>  <span class="c1"># Y è½´æ ‡ç­¾è¡¨ç¤º Query ä½ç½®</span>
    <span class="n">titles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Head </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>  <span class="c1"># ä¸ºæ¯ä¸ªæ³¨æ„åŠ›å¤´è®¾ç½®æ ‡é¢˜</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>  <span class="c1"># è®¾ç½®å›¾å½¢å¤§å°</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/120ec0719567d4212cb0f3ab71a959cdc781e78af0119de4de0420ba122f75a7.svg" src="../../_images/120ec0719567d4212cb0f3ab71a959cdc781e78af0119de4de0420ba122f75a7.svg" /></div>
</div>
<p>ä¸ç¼–ç å™¨çš„è‡ªæ³¨æ„åŠ›çš„æƒ…å†µç±»ä¼¼ï¼Œé€šè¿‡æŒ‡å®šè¾“å…¥åºåˆ—çš„æœ‰æ•ˆé•¿åº¦ï¼Œè¾“å‡ºåºåˆ—çš„æŸ¥è¯¢ä¸ä¼šä¸è¾“å…¥åºåˆ—ä¸­å¡«å……ä½ç½®çš„è¯å…ƒè¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä½¿ç”¨ d2l.show_heatmaps å‡½æ•°å¯è§†åŒ–è§£ç å™¨ä¸­ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›æƒé‡</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">show_heatmaps</span><span class="p">(</span>
    <span class="n">dec_inter_attention_weights</span><span class="p">,</span>  <span class="c1"># è§£ç å™¨ä¸­ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›æƒé‡</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Key positions&#39;</span><span class="p">,</span>  <span class="c1"># X è½´æ ‡ç­¾è¡¨ç¤º Key ä½ç½®</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Query positions&#39;</span><span class="p">,</span>  <span class="c1"># Y è½´æ ‡ç­¾è¡¨ç¤º Query ä½ç½®</span>
    <span class="n">titles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Head </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>  <span class="c1"># ä¸ºæ¯ä¸ªæ³¨æ„åŠ›å¤´è®¾ç½®æ ‡é¢˜</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>  <span class="c1"># è®¾ç½®å›¾å½¢å¤§å°</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/20feff643fca332950c749c769908bbda7f548a064daf86bc43fdd8ada26d183.svg" src="../../_images/20feff643fca332950c749c769908bbda7f548a064daf86bc43fdd8ada26d183.svg" /></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./NaturalLanguageProcessing/Transformer"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="end.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">å †å å¤šå±‚</p>
      </div>
    </a>
    <a class="right-next"
       href="../../FineTuning/Introduction.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">ä»€ä¹ˆæ˜¯å¾®è°ƒ</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#layernorm"><strong>LayerNorm è®¡ç®—</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#batchnorm1d">BatchNorm1d è®¡ç®—</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">ç¼–ç å™¨</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">å¤šå¤´æ³¨æ„åŠ›</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">ç¼–ç å™¨å—</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">è§£ç å™¨</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By ascotbe
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>