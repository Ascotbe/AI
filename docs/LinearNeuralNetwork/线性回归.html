
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>çº¿æ€§å›å½’ &#8212; AIå­¦ä¹ ç¬”è®°</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'LinearNeuralNetwork/çº¿æ€§å›å½’';</script>
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Softmax å›å½’åŸç†" href="Softmax%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86.html" />
    <link rel="prev" title="torch.meshgrid" href="../FunctionDetails/torch.meshgrid.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="AIå­¦ä¹ ç¬”è®° - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="AIå­¦ä¹ ç¬”è®° - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    ğŸ“š AI å­¦ä¹ ç¬”è®° ğŸ§ 
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">å‰ç½®çŸ¥è¯†</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../PrerequisiteKnowledge/%E5%BC%A0%E9%87%8F.html">å¼ é‡</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PrerequisiteKnowledge/%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6.html">å¹¿æ’­æœºåˆ¶</a></li>

<li class="toctree-l1"><a class="reference internal" href="../PrerequisiteKnowledge/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%BD%B4axis%E5%92%8Cdim.html">æ·±åº¦å­¦ä¹ ä¸­çš„è½´/axis/dimå…¨è§£</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PrerequisiteKnowledge/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC.html">è‡ªåŠ¨æ±‚å¯¼</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PrerequisiteKnowledge/%E5%85%B3%E4%BA%8Etensor%E4%B8%AD%E7%9A%84is_leaf.html">å…³äºtensorä¸­çš„is_leaf</a></li>

<li class="toctree-l1"><a class="reference internal" href="../PrerequisiteKnowledge/PyTorch%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86.html">PyTorchå›¾åƒå¤„ç†</a></li>




<li class="toctree-l1"><a class="reference internal" href="../PrerequisiteKnowledge/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html">æ¿€æ´»å‡½æ•°</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">å‡½æ•°è¯¦è§£</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../FunctionDetails/torch.argmax.html">torch.argmax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FunctionDetails/torch.matmul.html">torch.matmul</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FunctionDetails/torch.normal.html">torch.normal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FunctionDetails/torch.zeros.html">torch.zeros</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FunctionDetails/torch.nn.Linear.html">torch.nn.Linear</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FunctionDetails/torch.nn.ReLU.html">torch.nn.ReLU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FunctionDetails/torch.nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FunctionDetails/torch.arange.html">torch.arange</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FunctionDetails/torch.meshgrid.html">torch.meshgrid</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">çº¿æ€§ç¥ç»ç½‘ç»œ</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">çº¿æ€§å›å½’</a></li>








<li class="toctree-l1"><a class="reference internal" href="Softmax%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86.html">Softmax å›å½’åŸç†</a></li>


<li class="toctree-l1"><a class="reference internal" href="%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.html">äº¤å‰ç†µæŸå¤±å‡½æ•°åŸç†è¯¦è§£</a></li>
<li class="toctree-l1"><a class="reference internal" href="Softmax%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.html">Softmaxå›å½’ä»£ç å®ç°</a></li>








</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">å¤šå±‚æ„ŸçŸ¥æœº</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../MultilayerPerceptrons/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA.html">å¤šå±‚æ„ŸçŸ¥æœºçš„ç®€æ´å®ç°</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">æ·±åº¦å­¦ä¹ è®¡ç®—</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../DeepLearning/%E5%B1%82%E5%92%8C%E5%9D%97.html">å±‚å’Œå—</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DeepLearning/%E5%8F%82%E6%95%B0%E7%AE%A1%E7%90%86.html">å‚æ•°ç®¡ç†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DeepLearning/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82.html">è‡ªå®šä¹‰å±‚</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DeepLearning/%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6.html">è¯»å†™æ–‡ä»¶</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DeepLearning/GPU.html">GPU</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">å·ç§¯ç¥ç»ç½‘ç»œ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalNeuralNetwork/conv-layer.html">å›¾åƒå·ç§¯</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalNeuralNetwork/padding-and-strides.html">å¡«å……å’Œæ­¥å¹…</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalNeuralNetwork/channels.html">å¤šè¾“å…¥å¤šè¾“å‡ºé€šé“</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalNeuralNetwork/pooling.html">æ±‡èšå±‚</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalNeuralNetwork/lenet.html">å·ç§¯ç¥ç»ç½‘ç»œï¼ˆLeNetï¼‰</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ç°ä»£å·ç§¯ç¥ç»ç½‘ç»œ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalModern/alexnet.html">æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆAlexNetï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalModern/vgg.html">ä½¿ç”¨å—çš„ç½‘ç»œï¼ˆVGGï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalModern/nin.html">ç½‘ç»œä¸­çš„ç½‘ç»œï¼ˆNiNï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalModern/googlenet.html">å«å¹¶è¡Œè¿ç»“çš„ç½‘ç»œï¼ˆGoogLeNetï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalModern/resnet.html">æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalModern/batch-norm.html">æ‰¹é‡è§„èŒƒåŒ–</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ConvolutionalModern/densenet.html">ç¨ å¯†è¿æ¥ç½‘ç»œï¼ˆDenseNetï¼‰</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">è®¡ç®—æœºæ€§èƒ½</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ComputationalPerformance/async-computation.html">å¼‚æ­¥è®¡ç®—</a></li>


<li class="toctree-l1"><a class="reference internal" href="../ComputationalPerformance/parameterserver.html">å‚æ•°æœåŠ¡å™¨</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">è®¡ç®—æœºè§†è§‰</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ComputerVision/fine-tuning.html">å¾®è°ƒ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ComputerVision/bounding-box.html">ç›®æ ‡æ£€æµ‹å’Œè¾¹ç•Œæ¡†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ComputerVision/object-detection-dataset.html">ç›®æ ‡æ£€æµ‹æ•°æ®é›†</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/ascotbe/AI" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/LinearNeuralNetwork/çº¿æ€§å›å½’.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>çº¿æ€§å›å½’</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">çº¿æ€§å›å½’</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">ç”Ÿæˆæ•°æ®é›†</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">è¯»å–æ•°æ®é›†</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">åˆå§‹åŒ–æ¨¡å‹å‚æ•°</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">å®šä¹‰æ¨¡å‹</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">å®šä¹‰æŸå¤±å‡½æ•°</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">å®šä¹‰ä¼˜åŒ–ç®—æ³•</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">è®­ç»ƒ</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">å®Œæ•´ä»£ç </a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>çº¿æ€§å›å½’<a class="headerlink" href="#id1" title="Link to this heading">#</a></h1>
<blockquote>
<div><p>çº¿æ€§å›å½’æ ¸å¿ƒå°±æ˜¯åœ¨xå’Œyè½´ä¸­ï¼Œç»™å‡ºä¸€ä¸ªæ•°xä¼šæœ‰ç›¸å¯¹åº”çš„ä¸€ä¸ªyå€¼ã€‚æˆ‘ä»¬éœ€è¦å¾—åˆ°è¿™ä¸€ä¸ªæ¨¡å‹ï¼ˆé€šä¿—è¯´ï¼šä¸€ä¸ªç›´çº¿å…¬å¼ï¼‰ã€‚</p>
</div></blockquote>
<img src="../image/LinearNeuralNetwork/Linear_regression.svg" alt="" style="zoom: 90%; display: block; margin: 0px auto;" />
<p>åœ¨çº¿æ€§å›å½’ä¸­ï¼Œæ•°æ®ä½¿ç”¨çº¿æ€§é¢„æµ‹å‡½æ•°æ¥å»ºæ¨¡ï¼Œå¹¶ä¸”æœªçŸ¥çš„æ¨¡å‹å‚æ•°ä¹Ÿæ˜¯é€šè¿‡æ•°æ®æ¥ä¼°è®¡ã€‚è¿™äº›æ¨¡å‹è¢«å«åšçº¿æ€§æ¨¡å‹ã€‚æœ€å¸¸ç”¨çš„çº¿æ€§å›å½’å»ºæ¨¡æ˜¯ç»™å®šXå€¼çš„yçš„æ¡ä»¶å‡å€¼æ˜¯Xçš„ä»¿å°„å‡½æ•°ã€‚ä¸å¤ªä¸€èˆ¬çš„æƒ…å†µï¼Œçº¿æ€§å›å½’æ¨¡å‹å¯ä»¥æ˜¯ä¸€ä¸ªä¸­ä½æ•°æˆ–ä¸€äº›å…¶ä»–çš„ç»™å®šXçš„æ¡ä»¶ä¸‹yçš„æ¡ä»¶åˆ†å¸ƒçš„åˆ†ä½æ•°ä½œä¸ºXçš„çº¿æ€§å‡½æ•°è¡¨ç¤ºã€‚
çº¿æ€§å›å½’æœ‰å¾ˆå¤šå®é™…ç”¨é€”ã€‚åˆ†ä¸ºä»¥ä¸‹ä¸¤å¤§ç±»ï¼š</p>
<ol class="arabic simple">
<li><p>å¦‚æœç›®æ ‡æ˜¯é¢„æµ‹æˆ–è€…æ˜ å°„ï¼Œçº¿æ€§å›å½’å¯ä»¥ç”¨æ¥å¯¹è§‚æµ‹æ•°æ®é›†çš„å’ŒXçš„å€¼æ‹Ÿåˆå‡ºä¸€ä¸ªé¢„æµ‹æ¨¡å‹ã€‚å½“å®Œæˆè¿™æ ·ä¸€ä¸ªæ¨¡å‹ä»¥åï¼Œå¯¹äºä¸€ä¸ªæ–°å¢çš„Xå€¼ï¼Œåœ¨æ²¡æœ‰ç»™å®šä¸å®ƒç›¸é…å¯¹çš„yçš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ç”¨è¿™ä¸ªæ‹Ÿåˆè¿‡çš„æ¨¡å‹é¢„æµ‹å‡ºä¸€ä¸ªyå€¼ã€‚</p></li>
<li><p>ç»™å®šä¸€ä¸ªå˜é‡yå’Œä¸€äº›å˜é‡<span class="math notranslate nohighlight">\({\displaystyle X_{1}},...,{\displaystyle X_{p}}\)</span>ï¼Œè¿™äº›å˜é‡æœ‰å¯èƒ½ä¸yç›¸å…³ï¼Œçº¿æ€§å›å½’åˆ†æå¯ä»¥ç”¨æ¥é‡åŒ–yä¸Xjä¹‹é—´ç›¸å…³æ€§çš„å¼ºåº¦ï¼Œè¯„ä¼°å‡ºä¸yä¸ç›¸å…³çš„<span class="math notranslate nohighlight">\({\displaystyle X_{j}}\)</span>ï¼Œå¹¶è¯†åˆ«å‡ºå“ªäº›<span class="math notranslate nohighlight">\({\displaystyle X_{j}}\)</span>çš„å­é›†åŒ…å«äº†å…³äºyçš„å†—ä½™ä¿¡æ¯ã€‚</p></li>
</ol>
<p>è®­ç»ƒçš„è¿‡ç¨‹ä¸‹å›¾ä¼šæ›´ç›´è§‚çš„å±•ç¤º</p>
<div class="toggle docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">Callback</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dataset</span> <span class="k">as</span> <span class="n">ds</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">noise</span>
        <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">eval_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">get_data</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>
<span class="n">x_target_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="n">y_target_label</span> <span class="o">=</span> <span class="n">x_target_label</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span>
<span class="n">x_eval_label</span><span class="p">,</span><span class="n">y_eval_label</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">eval_data</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_eval_label</span><span class="p">,</span> <span class="n">y_eval_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_target_label</span><span class="p">,</span> <span class="n">y_target_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Eval data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">get_data</span><span class="p">(</span><span class="n">num_data</span><span class="p">)),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_data</span>
<span class="n">data_number</span> <span class="o">=</span> <span class="mi">1600</span>
<span class="n">batch_number</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">repeat_number</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">data_number</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_number</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="n">repeat_number</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The dataset size of ds_train:&quot;</span><span class="p">,</span> <span class="n">ds_train</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
<span class="n">dict_datasets</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">ds_train</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dict_datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The x label value shape:&quot;</span><span class="p">,</span> <span class="n">dict_datasets</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The y label value shape:&quot;</span><span class="p">,</span> <span class="n">dict_datasets</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
<span class="n">model_params</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_params</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
<span class="n">x_model_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="n">y_model_label</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_model_label</span> <span class="o">*</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span>
                 <span class="n">Tensor</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_eval_label</span><span class="p">,</span> <span class="n">y_eval_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_model_label</span><span class="p">,</span> <span class="n">y_model_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_target_label</span><span class="p">,</span> <span class="n">y_target_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
<span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_model_and_datasets</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">eval_data</span><span class="p">)</span>
    <span class="n">x_target</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">y_target</span> <span class="o">=</span> <span class="n">x_target</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_target</span><span class="p">,</span> <span class="n">y_target</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ImageShowCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span> <span class="o">=</span> <span class="n">eval_data</span>

    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">plot_model_and_datasets</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span><span class="p">)</span>
        <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">imageshow_cb</span> <span class="o">=</span> <span class="n">ImageShowCallback</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">imageshow_cb</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plot_model_and_datasets</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<img src="../image/LinearNeuralNetwork/linear_regression.gif" alt="" style="zoom: 90%; display: block; margin: 0px auto;" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id2">
<h1>ç”Ÿæˆæ•°æ®é›†<a class="headerlink" href="#id2" title="Link to this heading">#</a></h1>
<p>åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªåŒ…å«1000ä¸ªæ ·æœ¬çš„æ•°æ®é›†ï¼Œ
æ¯ä¸ªæ ·æœ¬åŒ…å«ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·çš„2ä¸ªç‰¹å¾ã€‚
æˆ‘ä»¬çš„åˆæˆæ•°æ®é›†æ˜¯ä¸€ä¸ªçŸ©é˜µ<span class="math notranslate nohighlight">\(\mathbf{X}\in \mathbb{R}^{1000 \times 2}\)</span>ã€‚</p>
<p>æˆ‘ä»¬ä½¿ç”¨çº¿æ€§æ¨¡å‹å‚æ•°<span class="math notranslate nohighlight">\(\mathbf{w} = [2, -3.4]^\top\)</span>ã€<span class="math notranslate nohighlight">\(b = 4.2\)</span>
å’Œå™ªå£°é¡¹<span class="math notranslate nohighlight">\(\epsilon\)</span>ç”Ÿæˆæ•°æ®é›†åŠå…¶æ ‡ç­¾ï¼š</p>
<div class="math notranslate nohighlight">
\[\mathbf{y}= \mathbf{X} \mathbf{w} + b + \mathbf\epsilon.\]</div>
<p><span class="math notranslate nohighlight">\(\epsilon\)</span>å¯ä»¥è§†ä¸ºæ¨¡å‹é¢„æµ‹å’Œæ ‡ç­¾æ—¶çš„æ½œåœ¨è§‚æµ‹è¯¯å·®ã€‚
åœ¨è¿™é‡Œæˆ‘ä»¬è®¤ä¸ºæ ‡å‡†å‡è®¾æˆç«‹ï¼Œå³<span class="math notranslate nohighlight">\(\epsilon\)</span>æœä»å‡å€¼ä¸º0çš„æ­£æ€åˆ†å¸ƒã€‚
ä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œæˆ‘ä»¬å°†æ ‡å‡†å·®è®¾ä¸º0.01ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">synthetic_data</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ç”Ÿæˆy=Xw+b+å™ªå£°&quot;&quot;&quot;</span>
    <span class="c1">#means (Tensor) â€“ å‡å€¼ï¼ˆå¹³å‡å€¼ï¼‰</span>
    <span class="c1">#std (Tensor) â€“ æ ‡å‡†å·® https://zh.wikihow.com/%E8%AE%A1%E7%AE%97%E6%A0%87%E5%87%86%E5%B7%AE</span>
    <span class="c1">#out (Tensor) â€“ å¯é€‰çš„è¾“å‡ºå¼ é‡</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">num_examples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1">#ä¸¤ä¸ªå¼ é‡çŸ©é˜µç›¸ä¹˜ï¼Œåœ¨PyTorchä¸­å¯ä»¥é€šè¿‡torch.matmulå‡½æ•°å®ç°</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
    <span class="c1">#print(y)</span>
    <span class="n">y</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1">#print(y)</span>
    <span class="c1">#torch.shape å’Œ torch.size()</span>
    <span class="c1">#-1è¡¨ç¤ºæ€»æ•°æ‰€åœ¨çš„ä½ç½®</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    
<span class="c1">#åˆ›å»ºå¼ é‡</span>
<span class="n">true_w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">true_w</span><span class="p">)</span>
<span class="n">true_b</span> <span class="o">=</span> <span class="mf">4.2</span>
<span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">synthetic_data</span><span class="p">(</span><span class="n">true_w</span><span class="p">,</span> <span class="n">true_b</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([ 2.0000, -3.4000])
tensor([[-0.1009,  0.8509],
        [-1.3132, -1.6724],
        [ 2.3128,  0.1308],
        ...,
        [-0.0139, -0.6867],
        [ 0.9515, -0.7639],
        [-1.3652, -1.3832]])
</pre></div>
</div>
</div>
</div>
<p>featuresä¸­çš„æ¯ä¸€è¡Œéƒ½åŒ…å«ä¸€ä¸ªäºŒç»´æ•°æ®æ ·æœ¬ï¼Œ labelsä¸­çš„æ¯ä¸€è¡Œéƒ½åŒ…å«ä¸€ç»´æ ‡ç­¾å€¼ï¼ˆä¸€ä¸ªæ ‡é‡ï¼‰</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;features:&#39;</span><span class="p">,</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">label:&#39;</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>features: tensor([-0.1009,  0.8509]) 
label: tensor([1.1126])
tensor([[-0.1009,  0.8509],
        [-1.3132, -1.6724],
        [ 2.3128,  0.1308],
        ...,
        [-0.0139, -0.6867],
        [ 0.9515, -0.7639],
        [-1.3652, -1.3832]])
</pre></div>
</div>
</div>
</div>
<p>é€šè¿‡ç”Ÿæˆç¬¬äºŒä¸ªç‰¹å¾features[:, 1]å’Œlabelsçš„æ•£ç‚¹å›¾ï¼Œ å¯ä»¥ç›´è§‚è§‚å¯Ÿåˆ°ä¸¤è€…ä¹‹é—´çš„çº¿æ€§å…³ç³»ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">features</span><span class="p">[:,</span> <span class="p">(</span><span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5a2ae351478234fe0ac45946d027c5cc20538198527452294a71145ef3f948db.svg" src="../_images/5a2ae351478234fe0ac45946d027c5cc20538198527452294a71145ef3f948db.svg" /></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id3">
<h1>è¯»å–æ•°æ®é›†<a class="headerlink" href="#id3" title="Link to this heading">#</a></h1>
<p>æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªdata_iterå‡½æ•°ï¼Œ è¯¥å‡½æ•°æ¥æ”¶æ‰¹é‡å¤§å°ã€ç‰¹å¾çŸ©é˜µå’Œæ ‡ç­¾å‘é‡ä½œä¸ºè¾“å…¥ï¼Œç”Ÿæˆå¤§å°ä¸ºbatch_sizeçš„å°æ‰¹é‡ã€‚ æ¯ä¸ªå°æ‰¹é‡åŒ…å«ä¸€ç»„ç‰¹å¾å’Œæ ‡ç­¾ã€‚</p>
<p>ä½¿ç”¨ä¸‹é¢ä»£ç çš„æ—¶å€™å…ˆé˜…è¯»ä¸‹ç”¨æ³•</p>
<p><strong>yueldç”¨æ³•</strong></p>
<p>ç›´æ¥å‚è€ƒ <a class="reference external" href="https://blog.csdn.net/mieleizhi0522/article/details/82142856/">https://blog.csdn.net/mieleizhi0522/article/details/82142856/</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">data_iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="c1">#print(num_examples)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">))</span>
    <span class="c1">#print(indices)</span>
    <span class="c1"># è¿™äº›æ ·æœ¬æ˜¯éšæœºè¯»å–çš„ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡ºåº,æ‰“ä¹±ä½ç½®</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>  <span class="c1"># ä»0å¼€å§‹æ¯æ¬¡+10è¿›è¡Œå¾ªç¯åˆ°1000ä¸ºæ­¢</span>
        <span class="n">batch_indices</span><span class="o">=</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">)]</span>  <span class="c1"># ä»1000ä¸ªéšæœºæ ·æœ¬é‡Œé¢å¼€å§‹å–å€¼ï¼Œæ¯æ¬¡å–å€¼èŒƒå›´æ˜¯[i:i+batch_size]         </span>
        <span class="c1">#print(batch_indices)</span>
        <span class="c1">#https://blog.csdn.net/mieleizhi0522/article/details/82142856/</span>
        <span class="k">yield</span> <span class="n">features</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">]</span>  <span class="c1"># è¿™ä¸ªå‡½æ•°è¡¨ç¤ºæ¯æ¬¡featureså’Œlabelséƒ½ä¼šå†²ä¸Šä¸€æ¬¡è¿›è¡Œæ¥ä¸‹å»,ç„¶åå–å€¼æ˜¯ç”¨ä¸Šé¢éšæœºæ ·æœ¬è¿›è¡Œç´¢å¼•çš„</span>
</pre></div>
</div>
</div>
</div>
<p>é€šå¸¸ï¼Œæˆ‘ä»¬åˆ©ç”¨GPUå¹¶è¡Œè¿ç®—çš„ä¼˜åŠ¿ï¼Œå¤„ç†åˆç†å¤§å°çš„â€œå°æ‰¹é‡â€ã€‚ æ¯ä¸ªæ ·æœ¬éƒ½å¯ä»¥å¹¶è¡Œåœ°è¿›è¡Œæ¨¡å‹è®¡ç®—ï¼Œä¸”æ¯ä¸ªæ ·æœ¬æŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¹Ÿå¯ä»¥è¢«å¹¶è¡Œè®¡ç®—ã€‚ GPUå¯ä»¥åœ¨å¤„ç†å‡ ç™¾ä¸ªæ ·æœ¬æ—¶ï¼Œæ‰€èŠ±è´¹çš„æ—¶é—´ä¸æ¯”å¤„ç†ä¸€ä¸ªæ ·æœ¬æ—¶å¤šå¤ªå¤šã€‚</p>
<p>æˆ‘ä»¬ç›´è§‚æ„Ÿå—ä¸€ä¸‹å°æ‰¹é‡è¿ç®—ï¼šè¯»å–ç¬¬ä¸€ä¸ªå°æ‰¹é‡æ•°æ®æ ·æœ¬å¹¶æ‰“å°ã€‚ æ¯ä¸ªæ‰¹é‡çš„ç‰¹å¾ç»´åº¦æ˜¾ç¤ºæ‰¹é‡å¤§å°å’Œè¾“å…¥ç‰¹å¾æ•°ã€‚ åŒæ ·çš„ï¼Œæ‰¹é‡çš„æ ‡ç­¾å½¢çŠ¶ä¸batch_sizeç›¸ç­‰ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-1.5851, -0.3377],
        [ 0.1086, -0.6178],
        [-1.1946,  1.6469],
        [ 0.5550, -1.2591],
        [ 0.0225,  1.0273],
        [-0.1791, -2.4304],
        [ 0.2051, -0.7662],
        [ 0.4129, -1.3818],
        [ 0.8814,  0.7540],
        [ 0.2028,  1.0184]]) 
 tensor([[ 2.1866],
        [ 6.5101],
        [-3.7776],
        [ 9.5880],
        [ 0.7465],
        [12.0921],
        [ 7.2298],
        [ 9.7099],
        [ 3.4076],
        [ 1.1454]])
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id4">
<h1>åˆå§‹åŒ–æ¨¡å‹å‚æ•°<a class="headerlink" href="#id4" title="Link to this heading">#</a></h1>
<p>åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä»å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º0.01çš„æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·éšæœºæ•°æ¥åˆå§‹åŒ–æƒé‡ï¼Œ å¹¶å°†åç½®åˆå§‹åŒ–ä¸º0ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id5">
<h1>å®šä¹‰æ¨¡å‹<a class="headerlink" href="#id5" title="Link to this heading">#</a></h1>
<p>æˆ‘ä»¬åªéœ€è®¡ç®—è¾“å…¥ç‰¹å¾<span class="math notranslate nohighlight">\(\mathbf{X}\)</span>å’Œæ¨¡å‹æƒé‡<span class="math notranslate nohighlight">\(\mathbf{w}\)</span>çš„çŸ©é˜µ-å‘é‡ä¹˜æ³•ååŠ ä¸Šåç½®<span class="math notranslate nohighlight">\(b\)</span>ã€‚
æ³¨æ„ï¼Œä¸Šé¢çš„<span class="math notranslate nohighlight">\(\mathbf{Xw}\)</span>æ˜¯ä¸€ä¸ªå‘é‡ï¼Œè€Œ<span class="math notranslate nohighlight">\(b\)</span>æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚
å›æƒ³ä¸€ä¸‹å¹¿æ’­æœºåˆ¶ï¼š
å½“æˆ‘ä»¬ç”¨ä¸€ä¸ªå‘é‡åŠ ä¸€ä¸ªæ ‡é‡æ—¶ï¼Œæ ‡é‡ä¼šè¢«åŠ åˆ°å‘é‡çš„æ¯ä¸ªåˆ†é‡ä¸Šã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">linreg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;çº¿æ€§å›å½’æ¨¡å‹&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id6">
<h1>å®šä¹‰æŸå¤±å‡½æ•°<a class="headerlink" href="#id6" title="Link to this heading">#</a></h1>
<p>å› ä¸ºéœ€è¦è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼Œæ‰€ä»¥æˆ‘ä»¬åº”è¯¥å…ˆå®šä¹‰æŸå¤±å‡½æ•°ã€‚åœ¨å®ç°ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å°†çœŸå®å€¼yçš„å½¢çŠ¶è½¬æ¢ä¸ºå’Œé¢„æµ‹å€¼y_hatçš„å½¢çŠ¶ç›¸åŒ</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">squared_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å‡æ–¹æŸå¤±&quot;&quot;&quot;</span>
    <span class="c1">#print(y_hat.shape)</span>
    <span class="c1">#print(y_hat)</span>
    <span class="c1">#çœŸå®å€¼yçš„å½¢çŠ¶è½¬æ¢ä¸ºå’Œé¢„æµ‹å€¼y_hatçš„å½¢çŠ¶ç›¸åŒ</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_hat</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id7">
<h1>å®šä¹‰ä¼˜åŒ–ç®—æ³•<a class="headerlink" href="#id7" title="Link to this heading">#</a></h1>
<p>ä¸‹é¢çš„å‡½æ•°å®ç°å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™æ›´æ–°ã€‚ è¯¥å‡½æ•°æ¥å—æ¨¡å‹å‚æ•°é›†åˆã€å­¦ä¹ é€Ÿç‡å’Œæ‰¹é‡å¤§å°ä½œä¸ºè¾“å…¥ã€‚æ¯ ä¸€æ­¥æ›´æ–°çš„å¤§å°ç”±å­¦ä¹ é€Ÿç‡lrå†³å®šã€‚ å› ä¸ºæˆ‘ä»¬è®¡ç®—çš„æŸå¤±æ˜¯ä¸€ä¸ªæ‰¹é‡æ ·æœ¬çš„æ€»å’Œï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨æ‰¹é‡å¤§å°ï¼ˆbatch_sizeï¼‰ æ¥è§„èŒƒåŒ–æ­¥é•¿ï¼Œè¿™æ ·æ­¥é•¿å¤§å°å°±ä¸ä¼šå–å†³äºæˆ‘ä»¬å¯¹æ‰¹é‡å¤§å°çš„é€‰æ‹©</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sgd</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™&quot;&quot;&quot;</span>
    <span class="c1">#with è¯­å¥é€‚ç”¨äºå¯¹èµ„æºè¿›è¡Œè®¿é—®çš„åœºåˆï¼Œç¡®ä¿ä¸ç®¡ä½¿ç”¨è¿‡ç¨‹ä¸­æ˜¯å¦å‘ç”Ÿå¼‚å¸¸éƒ½ä¼šæ‰§è¡Œå¿…è¦çš„â€œæ¸…ç†â€æ“ä½œï¼Œé‡Šæ”¾èµ„æºï¼Œæ¯”å¦‚æ–‡ä»¶ä½¿ç”¨åè‡ªåŠ¨å…³é—­ï¼çº¿ç¨‹ä¸­é”çš„è‡ªåŠ¨è·å–å’Œé‡Šæ”¾ç­‰ã€‚</span>
    <span class="c1"># no_gradç”¨æ¥å…³é—­æ¢¯åº¦è®¡ç®—</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">param</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">/</span> <span class="n">batch_size</span>
            <span class="c1">#éœ€è¦æ¸…ç†æ¢¯åº¦å€¼ä¸ç„¶ä¼šç´¯åŠ </span>
            <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id8">
<h1>è®­ç»ƒ<a class="headerlink" href="#id8" title="Link to this heading">#</a></h1>
<p>ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æ¨¡å‹è®­ç»ƒæ‰€æœ‰éœ€è¦çš„è¦ç´ ï¼Œå¯ä»¥å®ç°ä¸»è¦çš„è®­ç»ƒè¿‡ç¨‹éƒ¨åˆ†äº†ã€‚
ç†è§£è¿™æ®µä»£ç è‡³å…³é‡è¦ï¼Œå› ä¸ºä»äº‹æ·±åº¦å­¦ä¹ åï¼Œ
ç›¸åŒçš„è®­ç»ƒè¿‡ç¨‹å‡ ä¹ä¸€éåˆä¸€éåœ°å‡ºç°ã€‚
åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬è¯»å–ä¸€å°æ‰¹é‡è®­ç»ƒæ ·æœ¬ï¼Œå¹¶é€šè¿‡æˆ‘ä»¬çš„æ¨¡å‹æ¥è·å¾—ä¸€ç»„é¢„æµ‹ã€‚
è®¡ç®—å®ŒæŸå¤±åï¼Œæˆ‘ä»¬å¼€å§‹åå‘ä¼ æ’­ï¼Œå­˜å‚¨æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ã€‚
æœ€åï¼Œæˆ‘ä»¬è°ƒç”¨ä¼˜åŒ–ç®—æ³•<code class="docutils literal notranslate"><span class="pre">sgd</span></code>æ¥æ›´æ–°æ¨¡å‹å‚æ•°ã€‚</p>
<p>æ¦‚æ‹¬ä¸€ä¸‹ï¼Œæˆ‘ä»¬å°†æ‰§è¡Œä»¥ä¸‹å¾ªç¯ï¼š</p>
<ul class="simple">
<li><p>åˆå§‹åŒ–å‚æ•°</p></li>
<li><p>é‡å¤ä»¥ä¸‹è®­ç»ƒï¼Œç›´åˆ°å®Œæˆ</p>
<ul>
<li><p>è®¡ç®—æ¢¯åº¦<span class="math notranslate nohighlight">\(\mathbf{g} \leftarrow \partial_{(\mathbf{w},b)} \frac{1}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} l(\mathbf{x}^{(i)}, y^{(i)}, \mathbf{w}, b)\)</span></p></li>
<li><p>æ›´æ–°å‚æ•°<span class="math notranslate nohighlight">\((\mathbf{w}, b) \leftarrow (\mathbf{w}, b) - \eta \mathbf{g}\)</span></p></li>
</ul>
</li>
</ul>
<p>åœ¨æ¯ä¸ª<em>è¿­ä»£å‘¨æœŸ</em>ï¼ˆepochï¼‰ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨<code class="docutils literal notranslate"><span class="pre">data_iter</span></code>å‡½æ•°éå†æ•´ä¸ªæ•°æ®é›†ï¼Œ
å¹¶å°†è®­ç»ƒæ•°æ®é›†ä¸­æ‰€æœ‰æ ·æœ¬éƒ½ä½¿ç”¨ä¸€æ¬¡ï¼ˆå‡è®¾æ ·æœ¬æ•°èƒ½å¤Ÿè¢«æ‰¹é‡å¤§å°æ•´é™¤ï¼‰ã€‚
è¿™é‡Œçš„è¿­ä»£å‘¨æœŸä¸ªæ•°<code class="docutils literal notranslate"><span class="pre">num_epochs</span></code>å’Œå­¦ä¹ ç‡<code class="docutils literal notranslate"><span class="pre">lr</span></code>éƒ½æ˜¯è¶…å‚æ•°ï¼Œåˆ†åˆ«è®¾ä¸º3å’Œ0.03ã€‚
è®¾ç½®è¶…å‚æ•°å¾ˆæ£˜æ‰‹ï¼Œéœ€è¦é€šè¿‡åå¤è¯•éªŒè¿›è¡Œè°ƒæ•´ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.03</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">linreg</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">squared_loss</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="c1"># print(X)</span>
        <span class="c1"># print(y)</span>
        <span class="c1"># print(X.shape)</span>
        <span class="c1"># print(y.shape)</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># Xå’Œyçš„å°æ‰¹é‡æŸå¤±</span>
        <span class="c1"># å› ä¸ºlå½¢çŠ¶æ˜¯(batch_size,1)ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚lä¸­çš„æ‰€æœ‰å…ƒç´ è¢«åŠ åˆ°ä¸€èµ·ï¼Œ</span>
        <span class="c1"># å¹¶ä»¥æ­¤è®¡ç®—å…³äº[w,b]çš„æ¢¯åº¦</span>
        <span class="n">c</span><span class="o">=</span><span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="c1">#è¿™ä¸ªå€¼å¯ä»¥å¾ˆç›´è§‚çš„åæ˜ å‡ºé€æ¸ä¸‹é™</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">c</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">sgd</span><span class="p">([</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># ä½¿ç”¨å‚æ•°çš„æ¢¯åº¦æ›´æ–°å‚æ•°,å­¦ä¹ ç‡lræ˜¯0.03</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">train_l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, loss </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(92.2658, grad_fn=&lt;SumBackward0&gt;)
tensor(112.1879, grad_fn=&lt;SumBackward0&gt;)
tensor(139.8879, grad_fn=&lt;SumBackward0&gt;)
tensor(288.2449, grad_fn=&lt;SumBackward0&gt;)
tensor(179.3190, grad_fn=&lt;SumBackward0&gt;)
tensor(95.2094, grad_fn=&lt;SumBackward0&gt;)
tensor(64.7516, grad_fn=&lt;SumBackward0&gt;)
tensor(110.0334, grad_fn=&lt;SumBackward0&gt;)
tensor(43.7248, grad_fn=&lt;SumBackward0&gt;)
tensor(84.2513, grad_fn=&lt;SumBackward0&gt;)
tensor(76.9517, grad_fn=&lt;SumBackward0&gt;)
tensor(116.3255, grad_fn=&lt;SumBackward0&gt;)
tensor(84.7985, grad_fn=&lt;SumBackward0&gt;)
tensor(116.0920, grad_fn=&lt;SumBackward0&gt;)
tensor(42.9706, grad_fn=&lt;SumBackward0&gt;)
tensor(28.8140, grad_fn=&lt;SumBackward0&gt;)
tensor(87.8053, grad_fn=&lt;SumBackward0&gt;)
tensor(104.6961, grad_fn=&lt;SumBackward0&gt;)
tensor(60.1329, grad_fn=&lt;SumBackward0&gt;)
tensor(77.6993, grad_fn=&lt;SumBackward0&gt;)
tensor(44.2791, grad_fn=&lt;SumBackward0&gt;)
tensor(48.1772, grad_fn=&lt;SumBackward0&gt;)
tensor(43.9704, grad_fn=&lt;SumBackward0&gt;)
tensor(34.7604, grad_fn=&lt;SumBackward0&gt;)
tensor(23.1949, grad_fn=&lt;SumBackward0&gt;)
tensor(32.3768, grad_fn=&lt;SumBackward0&gt;)
tensor(39.7619, grad_fn=&lt;SumBackward0&gt;)
tensor(44.8695, grad_fn=&lt;SumBackward0&gt;)
tensor(17.0493, grad_fn=&lt;SumBackward0&gt;)
tensor(62.3201, grad_fn=&lt;SumBackward0&gt;)
tensor(40.4262, grad_fn=&lt;SumBackward0&gt;)
tensor(27.4084, grad_fn=&lt;SumBackward0&gt;)
tensor(21.6870, grad_fn=&lt;SumBackward0&gt;)
tensor(25.0690, grad_fn=&lt;SumBackward0&gt;)
tensor(20.3578, grad_fn=&lt;SumBackward0&gt;)
tensor(12.1300, grad_fn=&lt;SumBackward0&gt;)
tensor(8.7216, grad_fn=&lt;SumBackward0&gt;)
tensor(20.1629, grad_fn=&lt;SumBackward0&gt;)
tensor(24.6420, grad_fn=&lt;SumBackward0&gt;)
tensor(11.2134, grad_fn=&lt;SumBackward0&gt;)
tensor(12.6705, grad_fn=&lt;SumBackward0&gt;)
tensor(7.1136, grad_fn=&lt;SumBackward0&gt;)
tensor(22.7955, grad_fn=&lt;SumBackward0&gt;)
tensor(16.5830, grad_fn=&lt;SumBackward0&gt;)
tensor(11.2574, grad_fn=&lt;SumBackward0&gt;)
tensor(6.6075, grad_fn=&lt;SumBackward0&gt;)
tensor(4.5117, grad_fn=&lt;SumBackward0&gt;)
tensor(10.3217, grad_fn=&lt;SumBackward0&gt;)
tensor(9.8651, grad_fn=&lt;SumBackward0&gt;)
tensor(9.7901, grad_fn=&lt;SumBackward0&gt;)
tensor(2.4583, grad_fn=&lt;SumBackward0&gt;)
tensor(3.6208, grad_fn=&lt;SumBackward0&gt;)
tensor(6.7507, grad_fn=&lt;SumBackward0&gt;)
tensor(5.4716, grad_fn=&lt;SumBackward0&gt;)
tensor(1.6542, grad_fn=&lt;SumBackward0&gt;)
tensor(8.9868, grad_fn=&lt;SumBackward0&gt;)
tensor(5.0538, grad_fn=&lt;SumBackward0&gt;)
tensor(6.0581, grad_fn=&lt;SumBackward0&gt;)
tensor(3.6836, grad_fn=&lt;SumBackward0&gt;)
tensor(3.2481, grad_fn=&lt;SumBackward0&gt;)
tensor(3.8213, grad_fn=&lt;SumBackward0&gt;)
tensor(3.2105, grad_fn=&lt;SumBackward0&gt;)
tensor(4.4755, grad_fn=&lt;SumBackward0&gt;)
tensor(2.4113, grad_fn=&lt;SumBackward0&gt;)
tensor(4.1350, grad_fn=&lt;SumBackward0&gt;)
tensor(1.3312, grad_fn=&lt;SumBackward0&gt;)
tensor(2.1853, grad_fn=&lt;SumBackward0&gt;)
tensor(2.4151, grad_fn=&lt;SumBackward0&gt;)
tensor(2.1868, grad_fn=&lt;SumBackward0&gt;)
tensor(2.9987, grad_fn=&lt;SumBackward0&gt;)
tensor(1.8597, grad_fn=&lt;SumBackward0&gt;)
tensor(2.1233, grad_fn=&lt;SumBackward0&gt;)
tensor(1.0771, grad_fn=&lt;SumBackward0&gt;)
tensor(1.6114, grad_fn=&lt;SumBackward0&gt;)
tensor(0.9991, grad_fn=&lt;SumBackward0&gt;)
tensor(1.6638, grad_fn=&lt;SumBackward0&gt;)
tensor(1.3572, grad_fn=&lt;SumBackward0&gt;)
tensor(1.0322, grad_fn=&lt;SumBackward0&gt;)
tensor(0.4355, grad_fn=&lt;SumBackward0&gt;)
tensor(1.2230, grad_fn=&lt;SumBackward0&gt;)
tensor(1.0400, grad_fn=&lt;SumBackward0&gt;)
tensor(0.4340, grad_fn=&lt;SumBackward0&gt;)
tensor(0.9775, grad_fn=&lt;SumBackward0&gt;)
tensor(0.6314, grad_fn=&lt;SumBackward0&gt;)
tensor(0.6757, grad_fn=&lt;SumBackward0&gt;)
tensor(1.0385, grad_fn=&lt;SumBackward0&gt;)
tensor(0.7238, grad_fn=&lt;SumBackward0&gt;)
tensor(0.5117, grad_fn=&lt;SumBackward0&gt;)
tensor(0.4789, grad_fn=&lt;SumBackward0&gt;)
tensor(0.5395, grad_fn=&lt;SumBackward0&gt;)
tensor(0.8159, grad_fn=&lt;SumBackward0&gt;)
tensor(0.5133, grad_fn=&lt;SumBackward0&gt;)
tensor(0.6720, grad_fn=&lt;SumBackward0&gt;)
tensor(0.4495, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3599, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2650, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3021, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1900, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3469, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2194, grad_fn=&lt;SumBackward0&gt;)
epoch 1, loss 0.034264
tensor(0.2365, grad_fn=&lt;SumBackward0&gt;)
tensor(0.5088, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2619, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2261, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2955, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1911, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1784, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2104, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1721, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2115, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1786, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1302, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1231, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1318, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1358, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2141, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0907, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1621, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1148, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0789, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1599, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0737, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1330, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0458, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0705, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1022, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1234, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0498, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0383, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0565, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0538, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0832, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0790, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0555, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0406, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0366, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0338, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0372, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0488, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0344, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0226, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0307, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0694, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0211, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0298, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0134, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0175, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0199, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0114, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0236, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0256, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0168, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0096, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0148, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0203, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0103, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0123, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0092, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0117, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0074, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0113, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0150, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0092, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0061, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0057, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0080, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0096, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0052, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0051, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0082, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0061, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0081, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0034, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0056, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0025, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0041, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0019, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0018, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0027, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0024, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0039, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0030, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0021, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0038, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0027, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0017, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0041, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0023, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0033, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0021, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0023, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0033, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0025, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0017, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0024, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0026, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0013, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0015, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0013, grad_fn=&lt;SumBackward0&gt;)
epoch 2, loss 0.000119
tensor(0.0016, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0011, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0013, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0017, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0016, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0014, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0011, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0009, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0012, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0009, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0009, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0009, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0009, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0009, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
epoch 3, loss 0.000050
</pre></div>
</div>
</div>
</div>
<p>å› ä¸ºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯è‡ªå·±åˆæˆçš„æ•°æ®é›†ï¼Œæ‰€ä»¥æˆ‘ä»¬çŸ¥é“çœŸæ­£çš„å‚æ•°æ˜¯ä»€ä¹ˆã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ¯”è¾ƒçœŸå®å‚æ•°å’Œé€šè¿‡è®­ç»ƒå­¦åˆ°çš„å‚æ•°æ¥è¯„ä¼°è®­ç»ƒçš„æˆåŠŸç¨‹åº¦ã€‚ äº‹å®ä¸Šï¼ŒçœŸå®å‚æ•°å’Œé€šè¿‡è®­ç»ƒå­¦åˆ°çš„å‚æ•°ç¡®å®éå¸¸æ¥è¿‘ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;wçš„ä¼°è®¡è¯¯å·®: </span><span class="si">{</span><span class="n">true_w</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">true_w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;bçš„ä¼°è®¡è¯¯å·®: </span><span class="si">{</span><span class="n">true_b</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>wçš„ä¼°è®¡è¯¯å·®: tensor([1.6391e-04, 7.8678e-05], grad_fn=&lt;SubBackward0&gt;)
bçš„ä¼°è®¡è¯¯å·®: tensor([0.0003], grad_fn=&lt;RsubBackward1&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id9">
<h1>å®Œæ•´ä»£ç <a class="headerlink" href="#id9" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="k">def</span> <span class="nf">synthetic_data</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ç”Ÿæˆy=Xw+b+å™ªå£°&quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">num_examples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
    <span class="n">y</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">true_w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4</span><span class="p">])</span>
<span class="n">true_b</span> <span class="o">=</span> <span class="mf">4.2</span>
<span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">synthetic_data</span><span class="p">(</span><span class="n">true_w</span><span class="p">,</span> <span class="n">true_b</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>  <span class="c1">#ç”Ÿæˆç‰¹å¾å’Œæ ‡ç­¾</span>
<span class="k">def</span> <span class="nf">data_iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">))</span>
    <span class="c1"># è¿™äº›æ ·æœ¬æ˜¯éšæœºè¯»å–çš„ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡ºåº</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span> <span class="c1">#ä»0å¼€å§‹æ¯æ¬¡+10è¿›è¡Œå¾ªç¯åˆ°1000ä¸ºæ­¢</span>
        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">)])</span>  <span class="c1"># ä»1000ä¸ªéšæœºæ ·æœ¬é‡Œé¢å¼€å§‹å–å€¼ï¼Œæ¯æ¬¡å–å€¼èŒƒå›´æ˜¯[i:i+batch_size]</span>
        <span class="c1">#print(batch_indices)</span>
        <span class="k">yield</span> <span class="n">features</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">]</span>  <span class="c1">#è¿™ä¸ªå‡½æ•°è¡¨ç¤ºæ¯æ¬¡featureså’Œlabelséƒ½ä¼šå†²ä¸Šä¸€æ¬¡è¿›è¡Œæ¥ä¸‹å»,ç„¶åå–å€¼æ˜¯ç”¨ä¸Šé¢éšæœºæ ·æœ¬è¿›è¡Œç´¢å¼•çš„</span>



<span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">linreg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;çº¿æ€§å›å½’æ¨¡å‹&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
<span class="k">def</span> <span class="nf">squared_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å‡æ–¹æŸå¤±&quot;&quot;&quot;</span>
    <span class="c1">#æŸ¥çœ‹ç®—å‡ºæ¥çš„å€¼å’ŒåŸæ¥çš„æ ‡ç­¾æ¯”æŸå¤±å¤šå°‘</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_hat</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
<span class="k">def</span> <span class="nf">sgd</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span> <span class="c1">#å…ˆæ›´æ–°wç„¶åæ›´æ–°b</span>
            <span class="n">param</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">/</span> <span class="n">batch_size</span>
            <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>



<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="c1"># print(X)</span>
        <span class="c1"># print(y)</span>
        <span class="c1"># print(X.shape)</span>
        <span class="c1"># print(y.shape)</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">squared_loss</span><span class="p">(</span><span class="n">linreg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># Xå’Œyçš„å°æ‰¹é‡æŸå¤±</span>
        <span class="c1"># å› ä¸ºlå½¢çŠ¶æ˜¯(batch_size,1)ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚lä¸­çš„æ‰€æœ‰å…ƒç´ è¢«åŠ åˆ°ä¸€èµ·ï¼Œ</span>
        <span class="c1"># å¹¶ä»¥æ­¤è®¡ç®—å…³äº[w,b]çš„æ¢¯åº¦</span>
        <span class="n">c</span><span class="o">=</span><span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="c1">#è¿™ä¸ªå€¼å¯ä»¥å¾ˆç›´è§‚çš„åæ˜ å‡ºé€æ¸ä¸‹é™</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">c</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">sgd</span><span class="p">([</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># ä½¿ç”¨å‚æ•°çš„æ¢¯åº¦æ›´æ–°å‚æ•°ï¼Œå­¦ä¹ ç‡lræ˜¯0.03</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">train_l</span> <span class="o">=</span> <span class="n">squared_loss</span><span class="p">(</span><span class="n">linreg</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, loss </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;wçš„ä¼°è®¡è¯¯å·®: </span><span class="si">{</span><span class="n">true_w</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">true_w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;bçš„ä¼°è®¡è¯¯å·®: </span><span class="si">{</span><span class="n">true_b</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[823, 980, 728, 266, 903, 108, 230, 77, 902, 961, 45, 989, 319, 171, 55, 407, 369, 837, 127, 590, 308, 86, 403, 538, 708, 829, 437, 418, 82, 379, 158, 721, 526, 106, 351, 865, 422, 534, 681, 533, 142, 762, 259, 976, 620, 264, 750, 962, 143, 225, 781, 413, 509, 38, 684, 576, 43, 761, 104, 88, 148, 858, 565, 293, 453, 152, 420, 428, 735, 131, 107, 284, 69, 687, 563, 985, 102, 699, 194, 701, 743, 156, 632, 875, 394, 218, 244, 344, 242, 704, 317, 677, 249, 444, 410, 900, 639, 9, 822, 925, 827, 391, 174, 562, 447, 421, 765, 465, 147, 193, 76, 208, 826, 968, 656, 398, 140, 654, 312, 226, 359, 804, 564, 392, 696, 899, 796, 981, 791, 629, 691, 128, 543, 906, 358, 537, 881, 285, 841, 234, 161, 986, 575, 273, 409, 910, 65, 558, 277, 601, 972, 166, 767, 832, 393, 544, 689, 256, 474, 568, 22, 408, 456, 769, 805, 978, 513, 979, 146, 71, 645, 788, 818, 401, 18, 395, 469, 535, 574, 745, 503, 145, 343, 741, 507, 717, 820, 475, 955, 583, 138, 787, 658, 775, 595, 969, 941, 295, 921, 871, 187, 90, 510, 532, 738, 68, 808, 482, 91, 612, 306, 937, 957, 460, 96, 355, 164, 376, 511, 199, 648, 439, 912, 471, 263, 640, 594, 611, 893, 570, 996, 188, 548, 880, 83, 168, 217, 608, 801, 8, 436, 255, 476, 120, 270, 52, 445, 458, 967, 894, 867, 713, 951, 493, 353, 997, 365, 915, 809, 605, 763, 426, 381, 173, 862, 209, 450, 197, 335, 984, 375, 660, 554, 452, 802, 614, 245, 876, 337, 21, 299, 294, 907, 254, 977, 309, 523, 803, 214, 191, 797, 205, 789, 690, 192, 898, 286, 455, 364, 540, 855, 908, 224, 785, 849, 430, 633, 241, 637, 927, 870, 581, 159, 995, 470, 103, 240, 73, 390, 742, 936, 551, 904, 589, 709, 404, 853, 424, 883, 852, 644, 40, 446, 14, 643, 641, 10, 700, 662, 367, 634, 815, 553, 879, 354, 54, 642, 334, 132, 15, 272, 423, 624, 443, 868, 845, 812, 115, 206, 304, 840, 160, 615, 854, 585, 329, 724, 141, 110, 339, 834, 49, 833, 920, 943, 368, 163, 555, 185, 92, 901, 944, 773, 694, 129, 963, 307, 257, 547, 63, 397, 666, 878, 625, 5, 793, 0, 59, 604, 116, 385, 227, 357, 315, 628, 221, 661, 449, 715, 78, 683, 973, 897, 939, 863, 323, 821, 50, 783, 238, 754, 698, 964, 47, 768, 186, 216, 587, 688, 305, 559, 913, 170, 874, 488, 12, 261, 524, 850, 502, 671, 859, 342, 946, 917, 72, 711, 655, 121, 16, 931, 596, 1, 599, 965, 236, 400, 919, 930, 958, 975, 630, 135, 44, 695, 463, 51, 496, 702, 536, 887, 48, 149, 405, 291, 744, 873, 262, 231, 321, 336, 3, 891, 999, 389, 896, 371, 219, 756, 798, 326, 416, 417, 515, 93, 74, 472, 774, 61, 252, 726, 479, 37, 246, 126, 250, 737, 101, 57, 118, 579, 966, 303, 714, 734, 877, 545, 525, 288, 959, 467, 617, 712, 727, 647, 911, 196, 843, 938, 75, 489, 928, 934, 882, 519, 970, 122, 819, 725, 483, 794, 707, 777, 454, 441, 733, 751, 89, 411, 414, 626, 598, 806, 396, 124, 831, 828, 710, 346, 282, 619, 99, 64, 650, 857, 542, 736, 363, 720, 316, 616, 330, 42, 378, 125, 2, 7, 223, 265, 220, 914, 229, 719, 836, 844, 39, 942, 27, 182, 517, 276, 200, 419, 790, 247, 399, 11, 932, 20, 926, 184, 974, 732, 606, 136, 541, 350, 237, 506, 380, 490, 432, 500, 994, 318, 935, 473, 487, 860, 462, 731, 429, 749, 287, 112, 155, 748, 571, 747, 320, 697, 861, 520, 705, 154, 239, 592, 550, 758, 659, 233, 892, 528, 990, 169, 703, 179, 800, 310, 109, 311, 856, 153, 518, 459, 508, 842, 347, 17, 25, 557, 281, 895, 613, 609, 32, 31, 204, 348, 569, 603, 584, 998, 817, 566, 119, 341, 98, 621, 157, 280, 670, 824, 982, 435, 784, 498, 847, 113, 386, 137, 610, 289, 993, 663, 722, 425, 297, 30, 388, 779, 58, 760, 778, 947, 602, 556, 953, 678, 830, 869, 333, 539, 782, 636, 181, 580, 438, 764, 210, 652, 746, 494, 960, 434, 693, 13, 383, 62, 144, 680, 172, 331, 84, 139, 755, 952, 522, 130, 949, 668, 872, 956, 572, 646, 461, 560, 183, 811, 971, 66, 948, 905, 175, 4, 950, 497, 457, 105, 667, 356, 987, 412, 328, 302, 622, 924, 766, 448, 466, 260, 70, 314, 795, 301, 716, 491, 165, 349, 679, 635, 692, 664, 776, 792, 567, 228, 546, 29, 215, 34, 322, 477, 114, 933, 111, 669, 512, 672, 268, 150, 771, 864, 577, 890, 134, 85, 352, 35, 94, 258, 825, 485, 759, 480, 673, 799, 623, 195, 203, 631, 468, 269, 504, 406, 835, 373, 6, 178, 739, 675, 848, 527, 387, 478, 685, 279, 177, 888, 816, 807, 521, 366, 377, 813, 427, 582, 916, 362, 991, 929, 332, 597, 201, 451, 531, 686, 600, 325, 651, 372, 718, 753, 212, 374, 838, 190, 918, 682, 940, 79, 213, 300, 752, 431, 954, 586, 81, 780, 298, 202, 440, 674, 945, 923, 151, 340, 232, 23, 922, 573, 814, 433, 117, 514, 484, 275, 889, 267, 278, 36, 501, 41, 676, 464, 516, 345, 176, 649, 851, 274, 46, 53, 757, 415, 627, 839, 549, 248, 271, 653, 665, 618, 729, 222, 253, 740, 786, 772, 296, 189, 361, 100, 730, 810, 909, 382, 486, 60, 657, 706, 561, 235, 324, 180, 988, 384, 588, 593, 251, 97, 162, 123, 292, 133, 846, 578, 283, 327, 24, 884, 67, 95, 402, 499, 211, 885, 505, 992, 723, 87, 167, 207, 33, 360, 313, 552, 607, 290, 28, 370, 495, 481, 886, 80, 866, 638, 770, 529, 492, 198, 243, 983, 26, 530, 19, 442, 338, 591, 56]
tensor(91.2743, grad_fn=&lt;SumBackward0&gt;)
tensor(151.1160, grad_fn=&lt;SumBackward0&gt;)
tensor(122.0203, grad_fn=&lt;SumBackward0&gt;)
tensor(135.3613, grad_fn=&lt;SumBackward0&gt;)
tensor(108.5681, grad_fn=&lt;SumBackward0&gt;)
tensor(134.6382, grad_fn=&lt;SumBackward0&gt;)
tensor(89.6708, grad_fn=&lt;SumBackward0&gt;)
tensor(101.6971, grad_fn=&lt;SumBackward0&gt;)
tensor(78.8478, grad_fn=&lt;SumBackward0&gt;)
tensor(76.3622, grad_fn=&lt;SumBackward0&gt;)
tensor(123.2816, grad_fn=&lt;SumBackward0&gt;)
tensor(56.7232, grad_fn=&lt;SumBackward0&gt;)
tensor(64.6548, grad_fn=&lt;SumBackward0&gt;)
tensor(50.8422, grad_fn=&lt;SumBackward0&gt;)
tensor(90.5519, grad_fn=&lt;SumBackward0&gt;)
tensor(124.0426, grad_fn=&lt;SumBackward0&gt;)
tensor(48.0494, grad_fn=&lt;SumBackward0&gt;)
tensor(36.8736, grad_fn=&lt;SumBackward0&gt;)
tensor(117.0893, grad_fn=&lt;SumBackward0&gt;)
tensor(103.2491, grad_fn=&lt;SumBackward0&gt;)
tensor(31.3652, grad_fn=&lt;SumBackward0&gt;)
tensor(42.6806, grad_fn=&lt;SumBackward0&gt;)
tensor(36.3490, grad_fn=&lt;SumBackward0&gt;)
tensor(51.9007, grad_fn=&lt;SumBackward0&gt;)
tensor(37.7851, grad_fn=&lt;SumBackward0&gt;)
tensor(76.9579, grad_fn=&lt;SumBackward0&gt;)
tensor(28.2049, grad_fn=&lt;SumBackward0&gt;)
tensor(19.1354, grad_fn=&lt;SumBackward0&gt;)
tensor(18.1081, grad_fn=&lt;SumBackward0&gt;)
tensor(22.3057, grad_fn=&lt;SumBackward0&gt;)
tensor(22.5069, grad_fn=&lt;SumBackward0&gt;)
tensor(23.7637, grad_fn=&lt;SumBackward0&gt;)
tensor(30.7144, grad_fn=&lt;SumBackward0&gt;)
tensor(17.2448, grad_fn=&lt;SumBackward0&gt;)
tensor(27.6016, grad_fn=&lt;SumBackward0&gt;)
tensor(14.4210, grad_fn=&lt;SumBackward0&gt;)
tensor(15.9210, grad_fn=&lt;SumBackward0&gt;)
tensor(14.9422, grad_fn=&lt;SumBackward0&gt;)
tensor(17.9326, grad_fn=&lt;SumBackward0&gt;)
tensor(31.0603, grad_fn=&lt;SumBackward0&gt;)
tensor(17.1073, grad_fn=&lt;SumBackward0&gt;)
tensor(22.0580, grad_fn=&lt;SumBackward0&gt;)
tensor(18.2344, grad_fn=&lt;SumBackward0&gt;)
tensor(18.4943, grad_fn=&lt;SumBackward0&gt;)
tensor(11.0767, grad_fn=&lt;SumBackward0&gt;)
tensor(1.9923, grad_fn=&lt;SumBackward0&gt;)
tensor(5.2865, grad_fn=&lt;SumBackward0&gt;)
tensor(12.7993, grad_fn=&lt;SumBackward0&gt;)
tensor(13.9703, grad_fn=&lt;SumBackward0&gt;)
tensor(18.4979, grad_fn=&lt;SumBackward0&gt;)
tensor(18.5430, grad_fn=&lt;SumBackward0&gt;)
tensor(4.5737, grad_fn=&lt;SumBackward0&gt;)
tensor(5.3152, grad_fn=&lt;SumBackward0&gt;)
tensor(8.2751, grad_fn=&lt;SumBackward0&gt;)
tensor(12.9202, grad_fn=&lt;SumBackward0&gt;)
tensor(7.0023, grad_fn=&lt;SumBackward0&gt;)
tensor(6.8531, grad_fn=&lt;SumBackward0&gt;)
tensor(6.7458, grad_fn=&lt;SumBackward0&gt;)
tensor(7.1210, grad_fn=&lt;SumBackward0&gt;)
tensor(5.0924, grad_fn=&lt;SumBackward0&gt;)
tensor(1.7427, grad_fn=&lt;SumBackward0&gt;)
tensor(4.2105, grad_fn=&lt;SumBackward0&gt;)
tensor(6.0126, grad_fn=&lt;SumBackward0&gt;)
tensor(10.2124, grad_fn=&lt;SumBackward0&gt;)
tensor(3.5473, grad_fn=&lt;SumBackward0&gt;)
tensor(4.9903, grad_fn=&lt;SumBackward0&gt;)
tensor(3.7506, grad_fn=&lt;SumBackward0&gt;)
tensor(4.0490, grad_fn=&lt;SumBackward0&gt;)
tensor(6.4427, grad_fn=&lt;SumBackward0&gt;)
tensor(5.0340, grad_fn=&lt;SumBackward0&gt;)
tensor(2.8772, grad_fn=&lt;SumBackward0&gt;)
tensor(2.9797, grad_fn=&lt;SumBackward0&gt;)
tensor(2.0028, grad_fn=&lt;SumBackward0&gt;)
tensor(2.3304, grad_fn=&lt;SumBackward0&gt;)
tensor(1.6214, grad_fn=&lt;SumBackward0&gt;)
tensor(5.0479, grad_fn=&lt;SumBackward0&gt;)
tensor(2.5473, grad_fn=&lt;SumBackward0&gt;)
tensor(3.9275, grad_fn=&lt;SumBackward0&gt;)
tensor(2.8533, grad_fn=&lt;SumBackward0&gt;)
tensor(2.0716, grad_fn=&lt;SumBackward0&gt;)
tensor(1.4672, grad_fn=&lt;SumBackward0&gt;)
tensor(0.7919, grad_fn=&lt;SumBackward0&gt;)
tensor(1.3699, grad_fn=&lt;SumBackward0&gt;)
tensor(0.7636, grad_fn=&lt;SumBackward0&gt;)
tensor(2.6326, grad_fn=&lt;SumBackward0&gt;)
tensor(1.3324, grad_fn=&lt;SumBackward0&gt;)
tensor(0.5562, grad_fn=&lt;SumBackward0&gt;)
tensor(2.7292, grad_fn=&lt;SumBackward0&gt;)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.9037, grad_fn=&lt;SumBackward0&gt;)
tensor(1.6064, grad_fn=&lt;SumBackward0&gt;)
tensor(0.8658, grad_fn=&lt;SumBackward0&gt;)
tensor(0.6201, grad_fn=&lt;SumBackward0&gt;)
tensor(1.1863, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3988, grad_fn=&lt;SumBackward0&gt;)
tensor(0.8080, grad_fn=&lt;SumBackward0&gt;)
tensor(0.8200, grad_fn=&lt;SumBackward0&gt;)
tensor(0.6632, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3750, grad_fn=&lt;SumBackward0&gt;)
tensor(0.5612, grad_fn=&lt;SumBackward0&gt;)
tensor(0.5031, grad_fn=&lt;SumBackward0&gt;)
epoch 1, loss 0.047908
[415, 230, 157, 266, 68, 234, 453, 82, 653, 798, 399, 124, 243, 446, 911, 576, 556, 532, 77, 253, 988, 2, 843, 5, 395, 963, 233, 120, 133, 548, 496, 967, 213, 519, 910, 300, 527, 596, 32, 376, 436, 56, 813, 469, 984, 721, 417, 914, 614, 685, 642, 302, 800, 571, 46, 661, 716, 554, 626, 656, 830, 184, 389, 428, 111, 96, 280, 991, 61, 627, 222, 605, 814, 835, 735, 383, 143, 348, 180, 38, 335, 615, 873, 380, 533, 952, 377, 393, 678, 797, 387, 386, 60, 342, 702, 460, 741, 949, 221, 239, 738, 237, 481, 885, 700, 620, 578, 689, 675, 324, 671, 331, 641, 155, 775, 754, 717, 697, 774, 645, 531, 724, 622, 294, 505, 30, 441, 833, 935, 649, 733, 904, 646, 33, 503, 648, 112, 897, 974, 19, 200, 368, 886, 497, 540, 552, 78, 742, 29, 817, 690, 138, 902, 668, 132, 831, 207, 10, 75, 720, 750, 939, 178, 715, 332, 979, 177, 326, 600, 744, 826, 388, 594, 888, 734, 816, 236, 103, 916, 491, 304, 255, 406, 652, 558, 950, 480, 812, 451, 856, 524, 932, 70, 739, 841, 71, 369, 613, 6, 370, 913, 866, 123, 884, 550, 246, 692, 205, 514, 864, 947, 90, 699, 73, 18, 498, 127, 263, 340, 809, 756, 973, 905, 404, 45, 940, 74, 355, 459, 141, 858, 944, 515, 41, 464, 421, 7, 268, 625, 490, 561, 807, 868, 516, 93, 20, 920, 408, 977, 998, 168, 931, 211, 256, 192, 945, 870, 160, 545, 467, 249, 651, 282, 736, 679, 536, 149, 461, 271, 48, 311, 695, 284, 455, 116, 528, 828, 378, 493, 994, 566, 604, 173, 968, 790, 472, 281, 583, 964, 987, 565, 89, 848, 109, 580, 624, 603, 247, 618, 804, 452, 58, 166, 818, 443, 867, 272, 31, 608, 191, 539, 573, 504, 412, 877, 726, 91, 965, 640, 260, 427, 941, 195, 691, 669, 943, 769, 586, 889, 27, 609, 94, 402, 390, 793, 919, 456, 100, 701, 214, 711, 431, 50, 591, 636, 429, 712, 353, 660, 142, 621, 325, 164, 759, 14, 283, 385, 219, 72, 371, 226, 869, 928, 482, 688, 83, 543, 929, 158, 170, 942, 439, 709, 382, 896, 534, 853, 242, 321, 176, 262, 969, 298, 506, 163, 825, 696, 537, 992, 424, 432, 381, 803, 411, 879, 457, 495, 572, 957, 657, 837, 240, 862, 183, 520, 463, 562, 458, 215, 313, 307, 401, 806, 217, 703, 8, 322, 485, 422, 850, 672, 577, 276, 647, 98, 958, 983, 398, 606, 526, 327, 737, 474, 732, 589, 770, 203, 921, 196, 619, 232, 119, 909, 413, 758, 174, 265, 34, 961, 535, 779, 599, 344, 710, 492, 765, 581, 448, 666, 229, 364, 153, 881, 358, 361, 767, 44, 937, 343, 847, 275, 333, 292, 982, 901, 99, 147, 795, 341, 117, 161, 267, 238, 394, 876, 518, 462, 126, 337, 308, 575, 301, 151, 704, 953, 634, 47, 69, 288, 51, 277, 257, 644, 220, 632, 487, 113, 629, 162, 169, 223, 811, 22, 623, 667, 224, 287, 84, 549, 206, 477, 254, 323, 65, 954, 659, 789, 356, 523, 186, 707, 81, 218, 478, 976, 49, 602, 423, 584, 201, 500, 845, 934, 252, 365, 92, 210, 156, 560, 250, 861, 115, 64, 366, 122, 43, 751, 713, 0, 17, 290, 849, 28, 359, 719, 134, 655, 918, 791, 419, 351, 684, 454, 199, 823, 25, 470, 444, 764, 1, 42, 305, 727, 384, 336, 755, 360, 102, 912, 781, 959, 131, 139, 972, 989, 269, 900, 316, 479, 37, 538, 391, 593, 23, 435, 787, 810, 588, 903, 154, 264, 906, 136, 682, 125, 171, 130, 468, 270, 426, 551, 908, 278, 857, 698, 442, 612, 740, 53, 872, 574, 216, 101, 476, 962, 960, 917, 568, 396, 746, 637, 785, 925, 749, 9, 933, 728, 522, 824, 839, 899, 777, 776, 772, 894, 948, 788, 874, 513, 633, 834, 204, 15, 57, 895, 330, 529, 374, 851, 145, 838, 146, 639, 445, 936, 865, 802, 35, 763, 820, 339, 354, 569, 285, 971, 303, 289, 598, 114, 638, 13, 747, 363, 414, 409, 975, 483, 319, 643, 993, 440, 579, 212, 860, 430, 410, 258, 392, 416, 611, 286, 555, 16, 315, 852, 40, 512, 946, 801, 762, 990, 892, 118, 507, 670, 95, 107, 821, 129, 244, 997, 730, 542, 792, 291, 314, 299, 367, 4, 121, 855, 808, 59, 312, 595, 11, 784, 484, 36, 693, 352, 310, 167, 318, 447, 887, 21, 799, 197, 279, 783, 930, 397, 88, 66, 753, 610, 681, 137, 665, 546, 525, 510, 12, 729, 859, 501, 761, 63, 521, 630, 67, 658, 927, 714, 181, 24, 650, 907, 559, 547, 293, 475, 511, 731, 705, 189, 379, 923, 104, 893, 564, 165, 673, 329, 686, 687, 309, 628, 179, 677, 722, 228, 97, 922, 372, 854, 882, 822, 235, 148, 786, 592, 587, 295, 541, 400, 680, 144, 768, 434, 433, 955, 796, 508, 780, 840, 209, 846, 110, 773, 494, 827, 956, 771, 317, 999, 225, 175, 39, 502, 970, 52, 570, 437, 815, 863, 188, 819, 616, 320, 782, 898, 26, 182, 261, 159, 718, 106, 202, 635, 347, 128, 725, 350, 357, 172, 274, 449, 297, 405, 105, 836, 86, 241, 375, 883, 227, 706, 748, 743, 259, 373, 938, 664, 87, 418, 489, 471, 567, 273, 662, 152, 805, 338, 499, 296, 829, 582, 251, 563, 778, 190, 760, 62, 194, 198, 193, 150, 79, 345, 654, 349, 517, 708, 3, 55, 966, 757, 80, 951, 466, 880, 980, 509, 76, 981, 425, 420, 248, 924, 85, 842, 334, 890, 346, 996, 530, 871, 617, 438, 663, 674, 683, 844, 985, 585, 544, 54, 108, 915, 450, 676, 752, 607, 486, 878, 832, 328, 978, 986, 407, 140, 245, 995, 926, 553, 601, 362, 185, 208, 590, 891, 403, 875, 766, 465, 597, 745, 488, 557, 306, 631, 473, 794, 135, 187, 694, 231, 723]
tensor(0.3230, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3811, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1353, grad_fn=&lt;SumBackward0&gt;)
tensor(0.5864, grad_fn=&lt;SumBackward0&gt;)
tensor(0.5563, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2884, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2153, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3630, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3494, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2642, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2329, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2237, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2790, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3742, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1824, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1459, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1029, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0850, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2487, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1214, grad_fn=&lt;SumBackward0&gt;)
tensor(0.3826, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1755, grad_fn=&lt;SumBackward0&gt;)
tensor(0.2306, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1267, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0844, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0562, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0842, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1306, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1238, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0691, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1760, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0761, grad_fn=&lt;SumBackward0&gt;)
tensor(0.1614, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0568, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0899, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0347, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0982, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0233, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0731, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0996, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0491, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0421, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0666, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0300, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0437, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0424, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0387, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0744, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0243, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0498, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0224, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0265, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0317, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0212, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0214, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0216, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0221, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0078, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0166, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0255, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0180, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0120, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0118, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0173, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0177, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0272, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0147, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0120, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0112, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0082, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0092, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0034, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0116, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0065, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0080, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0030, grad_fn=&lt;SumBackward0&gt;)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.0080, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0110, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0055, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0060, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0042, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0026, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0036, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0052, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0041, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0040, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0036, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0015, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0055, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0021, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0061, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0017, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0038, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0030, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0022, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0038, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0028, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0038, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0022, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0023, grad_fn=&lt;SumBackward0&gt;)
epoch 2, loss 0.000222
[26, 915, 587, 901, 358, 310, 300, 743, 237, 425, 498, 471, 83, 318, 837, 775, 853, 306, 922, 402, 898, 534, 632, 663, 779, 336, 881, 554, 132, 362, 232, 438, 639, 71, 135, 591, 361, 273, 243, 673, 620, 757, 467, 953, 814, 942, 247, 792, 384, 324, 356, 89, 624, 843, 981, 131, 885, 855, 722, 789, 670, 389, 781, 691, 129, 328, 848, 288, 271, 55, 158, 78, 506, 355, 517, 409, 987, 252, 299, 248, 400, 85, 897, 202, 886, 426, 740, 667, 745, 698, 694, 81, 123, 603, 56, 251, 173, 576, 122, 571, 455, 17, 719, 991, 778, 289, 90, 457, 390, 388, 62, 678, 662, 46, 64, 687, 41, 965, 812, 825, 910, 537, 618, 343, 259, 883, 153, 74, 666, 316, 458, 347, 758, 443, 637, 0, 265, 422, 923, 978, 486, 165, 108, 552, 588, 561, 453, 614, 282, 215, 488, 513, 292, 795, 244, 386, 491, 344, 548, 567, 710, 709, 195, 977, 532, 478, 307, 955, 619, 392, 859, 286, 152, 495, 724, 224, 49, 340, 218, 539, 442, 514, 104, 995, 136, 334, 590, 254, 845, 15, 788, 557, 253, 54, 272, 76, 5, 656, 622, 401, 511, 968, 447, 280, 290, 462, 61, 33, 936, 311, 335, 144, 870, 332, 559, 466, 543, 516, 860, 175, 342, 583, 133, 188, 573, 294, 763, 279, 222, 676, 896, 975, 784, 689, 932, 785, 182, 109, 727, 27, 157, 613, 863, 476, 887, 496, 134, 733, 235, 954, 97, 305, 677, 688, 128, 480, 369, 720, 313, 634, 456, 360, 113, 435, 370, 9, 879, 114, 105, 19, 339, 354, 926, 540, 472, 32, 928, 515, 746, 345, 751, 508, 970, 873, 872, 385, 697, 682, 448, 625, 834, 600, 206, 707, 88, 621, 664, 762, 396, 258, 380, 405, 492, 179, 985, 714, 867, 996, 849, 723, 37, 725, 260, 301, 359, 207, 291, 341, 646, 553, 321, 914, 653, 474, 66, 147, 73, 500, 771, 240, 103, 40, 531, 794, 238, 181, 642, 44, 947, 94, 348, 315, 643, 296, 683, 586, 550, 875, 798, 761, 902, 13, 309, 320, 509, 137, 523, 601, 964, 423, 650, 197, 366, 542, 988, 198, 411, 949, 731, 379, 429, 807, 487, 661, 177, 806, 125, 140, 304, 774, 704, 43, 659, 927, 787, 822, 257, 421, 735, 329, 365, 742, 141, 14, 729, 419, 223, 151, 183, 512, 48, 549, 51, 242, 569, 375, 325, 527, 827, 372, 692, 424, 696, 58, 831, 703, 564, 521, 172, 303, 962, 752, 665, 990, 501, 180, 726, 87, 99, 888, 236, 693, 285, 256, 482, 904, 408, 644, 838, 162, 744, 250, 801, 749, 737, 780, 929, 572, 214, 270, 627, 2, 277, 992, 952, 903, 164, 353, 484, 734, 546, 485, 333, 943, 971, 126, 575, 766, 21, 606, 790, 227, 631, 802, 420, 889, 233, 50, 864, 57, 234, 562, 427, 11, 941, 930, 551, 713, 556, 973, 412, 34, 100, 581, 216, 373, 490, 84, 255, 959, 890, 12, 668, 213, 16, 228, 510, 836, 82, 378, 680, 186, 760, 63, 59, 912, 317, 967, 91, 7, 716, 112, 615, 31, 895, 519, 28, 302, 865, 535, 924, 116, 755, 106, 577, 919, 22, 20, 538, 208, 782, 117, 706, 593, 841, 72, 397, 168, 582, 715, 483, 80, 765, 877, 957, 882, 38, 800, 187, 705, 828, 649, 599, 111, 728, 638, 295, 269, 444, 920, 327, 685, 612, 391, 605, 77, 403, 184, 469, 146, 437, 159, 204, 908, 648, 120, 623, 433, 398, 674, 818, 958, 960, 191, 641, 753, 338, 155, 916, 246, 876, 70, 993, 921, 630, 149, 628, 220, 878, 170, 199, 611, 909, 382, 65, 570, 816, 933, 690, 547, 68, 617, 130, 944, 95, 276, 174, 857, 449, 945, 67, 741, 287, 856, 178, 999, 699, 983, 86, 911, 322, 884, 119, 899, 470, 893, 330, 948, 768, 568, 166, 852, 473, 773, 8, 796, 738, 268, 29, 413, 481, 209, 312, 127, 759, 461, 363, 777, 196, 440, 558, 931, 647, 592, 580, 60, 394, 454, 815, 712, 148, 545, 494, 750, 636, 976, 124, 824, 451, 651, 203, 721, 597, 686, 326, 578, 835, 972, 505, 654, 219, 410, 585, 940, 672, 791, 819, 946, 431, 718, 997, 854, 121, 351, 416, 616, 711, 230, 262, 811, 808, 445, 192, 171, 604, 574, 261, 950, 858, 608, 823, 681, 702, 701, 826, 139, 529, 323, 842, 475, 79, 804, 635, 35, 281, 226, 169, 138, 368, 101, 36, 839, 717, 832, 231, 221, 754, 308, 193, 610, 278, 530, 913, 595, 92, 984, 961, 376, 544, 352, 42, 900, 989, 463, 212, 118, 803, 951, 820, 633, 596, 607, 357, 748, 53, 786, 460, 817, 297, 810, 249, 536, 533, 93, 387, 381, 374, 211, 679, 393, 217, 404, 793, 189, 526, 847, 479, 145, 589, 229, 907, 142, 418, 156, 994, 459, 871, 938, 201, 566, 96, 417, 584, 700, 905, 524, 210, 846, 555, 805, 39, 452, 986, 925, 868, 406, 241, 434, 190, 565, 675, 504, 30, 917, 966, 383, 185, 776, 314, 415, 799, 998, 809, 430, 337, 10, 956, 671, 969, 640, 520, 963, 4, 657, 465, 377, 464, 906, 563, 598, 75, 935, 730, 684, 275, 783, 739, 468, 874, 829, 24, 862, 833, 861, 161, 239, 695, 708, 331, 502, 150, 200, 499, 937, 579, 176, 407, 609, 769, 891, 756, 107, 830, 477, 160, 69, 441, 371, 518, 767, 267, 507, 497, 225, 115, 655, 594, 436, 602, 263, 346, 450, 660, 979, 652, 918, 522, 732, 525, 163, 669, 541, 98, 880, 892, 6, 194, 349, 18, 772, 645, 560, 764, 770, 274, 143, 851, 980, 840, 245, 528, 298, 866, 489, 797, 399, 283, 974, 747, 350, 23, 47, 110, 319, 154, 264, 658, 821, 934, 45, 869, 25, 3, 503, 102, 626, 1, 52, 939, 813, 736, 844, 439, 414, 167, 629, 894, 493, 982, 428, 284, 293, 364, 432, 395, 205, 367, 446, 850, 266]
tensor(0.0043, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0027, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0014, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0019, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0025, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0012, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0023, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0019, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0012, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0019, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0016, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0031, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0012, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0011, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0024, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0012, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0017, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0011, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0011, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0014, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0011, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0010, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0009, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0011, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0009, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0011, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0008, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0009, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0005, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0007, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0004, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0002, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0006, grad_fn=&lt;SumBackward0&gt;)
tensor(0.0003, grad_fn=&lt;SumBackward0&gt;)
epoch 3, loss 0.000050
wçš„ä¼°è®¡è¯¯å·®: tensor([-0.0004, -0.0017], grad_fn=&lt;SubBackward0&gt;)
bçš„ä¼°è®¡è¯¯å·®: tensor([0.0016], grad_fn=&lt;RsubBackward1&gt;)
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./LinearNeuralNetwork"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../FunctionDetails/torch.meshgrid.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">torch.meshgrid</p>
      </div>
    </a>
    <a class="right-next"
       href="Softmax%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Softmax å›å½’åŸç†</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">çº¿æ€§å›å½’</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">ç”Ÿæˆæ•°æ®é›†</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">è¯»å–æ•°æ®é›†</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">åˆå§‹åŒ–æ¨¡å‹å‚æ•°</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">å®šä¹‰æ¨¡å‹</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">å®šä¹‰æŸå¤±å‡½æ•°</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">å®šä¹‰ä¼˜åŒ–ç®—æ³•</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">è®­ç»ƒ</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">å®Œæ•´ä»£ç </a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By ascotbe
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>